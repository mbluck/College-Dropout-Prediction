{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discovered during EDA, there is high multicolinearity in our feature set. We'll reference the association heatmaps in the EDA notebook. \n",
    "\n",
    "To begin, we'll address the redundancy between 'Admission grade' and 'Previous qualification (grade)' by removing whichever one has lower mutual information with the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission grade: [0.02852458]\n",
      "Previous qualification (grade): [0.0357418]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('LogReg/X.csv')\n",
    "y = pd.read_csv('LogReg/y.csv')\n",
    "\n",
    "y_np = y.to_numpy()\n",
    "y_np = y_np.ravel()\n",
    "\n",
    "ag = mutual_info_classif(X['Admission grade'].to_frame(), y_np, discrete_features=False, random_state=1)\n",
    "pqg = mutual_info_classif(X['Previous qualification (grade)'].to_frame(), y_np, discrete_features=False, random_state=1)\n",
    "\n",
    "print(f'Admission grade: {ag}\\nPrevious qualification (grade): {pqg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove 'Admission grade'.\n",
    "\n",
    "We'll also remove 'International' because it's completely redundant with 'Nationality' but provides less information.\n",
    "\n",
    "Next, we'll address the fact that 'Course' and 'Daytime/evening attendance' are one for one associated. We'll remove 'Daytime/evening attendance' because it's redundant with 'Course', which contains more information.\n",
    "\n",
    "Curricular units (enrolled), for both 1st and 2nd semesters, are highly associated with 'Course'. However, we should be careful about removing either since they provide very different types of information. Let's compare their relatinships to the target using mutual information. We can't compare VIF scores since one feature is categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: [0.03455513]\n",
      "Curricular units 1st sem (enrolled): [0.02378636]\n"
     ]
    }
   ],
   "source": [
    "# COMPARE MUTUAL INFORMATION\n",
    "c = mutual_info_classif(X['Course'].to_frame(), y_np, discrete_features=True, random_state=1)\n",
    "cu = mutual_info_classif(X['Curricular units 1st sem (enrolled)'].to_frame(), y_np, discrete_features=False, random_state=1)\n",
    "\n",
    "print(f'Course: {c}\\nCurricular units 1st sem (enrolled): {cu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE REDUNDANT FEATURES\n",
    "\n",
    "X = X.drop(['Admission grade', 'Daytime/evening attendance', 'International'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still not clear if it's suitable to remove one or the other. Let's keep both for now and choose one based on model performance later.\n",
    "\n",
    "Now we need to address the high multicolinearity among all the features measuring curricular units. Let's try using PCA.<br>\n",
    "First, we'll try PCA using all the features. This probably won't yield good results as most of the features aren't correlated amongst each other. Then, we'll try using subset PCA, wherein only the curricular unit features are transformed and the other features are left unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:\n",
      "[9.99840289e-01 7.80459674e-05 4.11694210e-05]\n",
      "\n",
      "Curr Units features:\n",
      "[0.64980168 0.25016538 0.05229662]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "curr_units = [\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)'\n",
    "]\n",
    "\n",
    "# ALL FEATURES\n",
    "pca_all = PCA(n_components=3)\n",
    "pca_all.fit(X)\n",
    "\n",
    "# CURR UNITS FEATURES\n",
    "pca_cu = PCA(n_components=3)\n",
    "pca_cu.fit(X[curr_units])\n",
    "\n",
    "print(f'All features:\\n{pca_all.explained_variance_ratio_}\\n\\nCurr Units features:\\n{pca_cu.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components of pca_all explain almost no variance, whereas the first two components of pca_cu explain 90% of it. We'll replace all the curricular unit features with these two components. This also resolves the 'Curricular units (enrolled)' vs 'Course' issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE CURR UNITS FEATURES WITH PRINCIPLE COMPONENTS\n",
    "\n",
    "pca_cu = PCA(n_components=2)\n",
    "transformed = pca_cu.fit_transform(X[curr_units])\n",
    "\n",
    "pca_df = pd.DataFrame(transformed, columns=[f'Curr units PC{i+1}' for i in range(transformed.shape[1])])\n",
    "X = X.drop(curr_units, axis=1)\n",
    "X = pd.concat([X, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marital status', 'Application mode', 'Application order', 'Course',\n",
       "       'Previous qualification', 'Previous qualification (grade)',\n",
       "       'Nationality', 'Mother's qualification', 'Father's qualification',\n",
       "       'Mother's occupation', 'Father's occupation', 'Displaced',\n",
       "       'Educational special needs', 'Debtor', 'Tuition fees up to date',\n",
       "       'Gender', 'Scholarship holder', 'Age at enrollment',\n",
       "       'Unemployment rate', 'Inflation rate', 'GDP', 'Curr units PC1',\n",
       "       'Curr units PC2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we model, let's define functions for scaling and one-hot encoding the data that will handle the combination of categorical and numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Function to scale data without altering nominal features.\n",
    "Takes 'df' (a dataframe) and 'nominal' (a list of nominal feature names).\n",
    "Returns the transformed dataframe. \n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale(df, nominal):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    for var in df.columns:\n",
    "            \n",
    "        if var not in nominal:\n",
    "            raw = df[var].to_numpy()\n",
    "            raw = raw.reshape(-1, 1)\n",
    "\n",
    "            scaler.fit(raw)\n",
    "            scaled = scaler.transform(raw)\n",
    "            df[var] = scaled\n",
    "\n",
    "    return df\n",
    "\n",
    "nominal = ['Marital status', 'Application mode', 'Course',\n",
    "           'Previous qualification', 'Nationality', \n",
    "           \"Mother's qualification\", \"Father's qualification\",\n",
    "           \"Mother's occupation\", \"Father's occupation\", 'Displaced', \n",
    "           'Educational special needs', 'Debtor', 'Tuition fees up to date', \n",
    "           'Gender', 'Scholarship holder']\n",
    "\n",
    "X = scale(X, nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "encoder = TargetEncoder(cols=nominal)\n",
    "\n",
    "X = encoder.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   No. Observations:                 4424\n",
      "Model:                          Logit   Df Residuals:                     4400\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Wed, 06 Nov 2024   Pseudo R-squ.:                  0.4200\n",
      "Time:                        13:33:55   Log-Likelihood:                -1611.0\n",
      "converged:                      False   LL-Null:                       -2777.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "const                              0.6120     11.326      0.054      0.957     -21.587      22.811\n",
      "Marital status                    -2.3379      1.068     -2.189      0.029      -4.432      -0.244\n",
      "Application mode                   2.4139      0.492      4.909      0.000       1.450       3.378\n",
      "Application order                  1.0945      0.346      3.163      0.002       0.416       1.773\n",
      "Course                             2.5808      0.413      6.255      0.000       1.772       3.390\n",
      "Previous qualification             0.7550      0.538      1.404      0.160      -0.299       1.809\n",
      "Previous qualification (grade)    -0.6916      0.329     -2.099      0.036      -1.337      -0.046\n",
      "Nationality                        1.9690      4.394      0.448      0.654      -6.643      10.581\n",
      "Mother's qualification             2.0590      0.674      3.056      0.002       0.739       3.379\n",
      "Father's qualification             0.8585      0.717      1.198      0.231      -0.546       2.263\n",
      "Mother's occupation                1.4580      0.746      1.956      0.051      -0.003       2.919\n",
      "Father's occupation                0.8270      0.818      1.011      0.312      -0.776       2.430\n",
      "Displaced                         -1.9060      1.028     -1.853      0.064      -3.922       0.110\n",
      "Educational special needs          0.2624     34.876      0.008      0.994     -68.094      68.618\n",
      "Debtor                             1.2822      0.439      2.920      0.003       0.422       2.143\n",
      "Tuition fees up to date            4.0594      0.269     15.109      0.000       3.533       4.586\n",
      "Gender                             1.5642      0.478      3.276      0.001       0.628       2.500\n",
      "Scholarship holder                 3.0805      0.483      6.382      0.000       2.135       4.027\n",
      "Age at enrollment                  0.4738      0.410      1.154      0.248      -0.331       1.278\n",
      "Unemployment rate                  0.5945      0.166      3.586      0.000       0.270       0.919\n",
      "Inflation rate                     0.0470      0.150      0.314      0.754      -0.247       0.341\n",
      "GDP                                0.1484      0.167      0.888      0.374      -0.179       0.476\n",
      "Curr units PC1                    -6.3816      0.308    -20.714      0.000      -6.985      -5.778\n",
      "Curr units PC2                    -7.9645      0.429    -18.558      0.000      -8.806      -7.123\n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# preprocess\n",
    "nominal = ['Marital status', 'Application mode', 'Course',\n",
    "       'Previous qualification', 'Nationality', \"Mother's qualification\", \n",
    "       \"Father's qualification\", \"Mother's occupation\", \"Father's occupation\", \n",
    "       'Displaced', 'Educational special needs', 'Debtor', \n",
    "       'Tuition fees up to date','Gender', 'Scholarship holder']\n",
    "\n",
    "# add intercept\n",
    "X_intp = sm.add_constant(X)\n",
    "\n",
    "# fit\n",
    "clf = sm.Logit(y, X_intp)\n",
    "clf_fit = clf.fit(method='lbfgs') # binary features mean the model won't converge with default regularization\n",
    "\n",
    "# summary stats\n",
    "print(clf_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err.</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>0.612003</td>\n",
       "      <td>11.326093</td>\n",
       "      <td>0.054035</td>\n",
       "      <td>9.569074e-01</td>\n",
       "      <td>-21.586732</td>\n",
       "      <td>22.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marital status</td>\n",
       "      <td>-2.337882</td>\n",
       "      <td>1.068211</td>\n",
       "      <td>-2.188596</td>\n",
       "      <td>2.862623e-02</td>\n",
       "      <td>-4.431538</td>\n",
       "      <td>-0.244227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>2.413850</td>\n",
       "      <td>0.491696</td>\n",
       "      <td>4.909231</td>\n",
       "      <td>9.143406e-07</td>\n",
       "      <td>1.450143</td>\n",
       "      <td>3.377557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Application order</td>\n",
       "      <td>1.094498</td>\n",
       "      <td>0.346036</td>\n",
       "      <td>3.162959</td>\n",
       "      <td>1.561743e-03</td>\n",
       "      <td>0.416280</td>\n",
       "      <td>1.772717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Course</td>\n",
       "      <td>2.580834</td>\n",
       "      <td>0.412632</td>\n",
       "      <td>6.254562</td>\n",
       "      <td>3.986319e-10</td>\n",
       "      <td>1.772089</td>\n",
       "      <td>3.389578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Previous qualification</td>\n",
       "      <td>0.754953</td>\n",
       "      <td>0.537626</td>\n",
       "      <td>1.404234</td>\n",
       "      <td>1.602492e-01</td>\n",
       "      <td>-0.298775</td>\n",
       "      <td>1.808681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>-0.691580</td>\n",
       "      <td>0.329436</td>\n",
       "      <td>-2.099284</td>\n",
       "      <td>3.579186e-02</td>\n",
       "      <td>-1.337262</td>\n",
       "      <td>-0.045897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nationality</td>\n",
       "      <td>1.969008</td>\n",
       "      <td>4.393843</td>\n",
       "      <td>0.448129</td>\n",
       "      <td>6.540602e-01</td>\n",
       "      <td>-6.642767</td>\n",
       "      <td>10.580783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mother's qualification</td>\n",
       "      <td>2.059045</td>\n",
       "      <td>0.673707</td>\n",
       "      <td>3.056290</td>\n",
       "      <td>2.240941e-03</td>\n",
       "      <td>0.738603</td>\n",
       "      <td>3.379487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Father's qualification</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.716629</td>\n",
       "      <td>1.198005</td>\n",
       "      <td>2.309152e-01</td>\n",
       "      <td>-0.546042</td>\n",
       "      <td>2.263091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mother's occupation</td>\n",
       "      <td>1.458045</td>\n",
       "      <td>0.745539</td>\n",
       "      <td>1.955692</td>\n",
       "      <td>5.050142e-02</td>\n",
       "      <td>-0.003185</td>\n",
       "      <td>2.919274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Father's occupation</td>\n",
       "      <td>0.827030</td>\n",
       "      <td>0.817823</td>\n",
       "      <td>1.011257</td>\n",
       "      <td>3.118933e-01</td>\n",
       "      <td>-0.775874</td>\n",
       "      <td>2.429934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Displaced</td>\n",
       "      <td>-1.906002</td>\n",
       "      <td>1.028469</td>\n",
       "      <td>-1.853242</td>\n",
       "      <td>6.384775e-02</td>\n",
       "      <td>-3.921764</td>\n",
       "      <td>0.109761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Educational special needs</td>\n",
       "      <td>0.262401</td>\n",
       "      <td>34.876156</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>9.939969e-01</td>\n",
       "      <td>-68.093609</td>\n",
       "      <td>68.618410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>1.282227</td>\n",
       "      <td>0.439110</td>\n",
       "      <td>2.920057</td>\n",
       "      <td>3.499677e-03</td>\n",
       "      <td>0.421587</td>\n",
       "      <td>2.142868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>4.059363</td>\n",
       "      <td>0.268665</td>\n",
       "      <td>15.109368</td>\n",
       "      <td>1.404807e-51</td>\n",
       "      <td>3.532789</td>\n",
       "      <td>4.585937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.564167</td>\n",
       "      <td>0.477523</td>\n",
       "      <td>3.275586</td>\n",
       "      <td>1.054429e-03</td>\n",
       "      <td>0.628240</td>\n",
       "      <td>2.500095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>3.080544</td>\n",
       "      <td>0.482659</td>\n",
       "      <td>6.382449</td>\n",
       "      <td>1.742783e-10</td>\n",
       "      <td>2.134550</td>\n",
       "      <td>4.026537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>0.473789</td>\n",
       "      <td>0.410489</td>\n",
       "      <td>1.154207</td>\n",
       "      <td>2.484154e-01</td>\n",
       "      <td>-0.330754</td>\n",
       "      <td>1.278333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>0.594506</td>\n",
       "      <td>0.165763</td>\n",
       "      <td>3.586477</td>\n",
       "      <td>3.351759e-04</td>\n",
       "      <td>0.269616</td>\n",
       "      <td>0.919395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Inflation rate</td>\n",
       "      <td>0.046990</td>\n",
       "      <td>0.149853</td>\n",
       "      <td>0.313576</td>\n",
       "      <td>7.538434e-01</td>\n",
       "      <td>-0.246716</td>\n",
       "      <td>0.340697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GDP</td>\n",
       "      <td>0.148415</td>\n",
       "      <td>0.167115</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>3.744841e-01</td>\n",
       "      <td>-0.179123</td>\n",
       "      <td>0.475954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Curr units PC1</td>\n",
       "      <td>-6.381557</td>\n",
       "      <td>0.308080</td>\n",
       "      <td>-20.713968</td>\n",
       "      <td>2.591998e-95</td>\n",
       "      <td>-6.985383</td>\n",
       "      <td>-5.777732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Curr units PC2</td>\n",
       "      <td>-7.964496</td>\n",
       "      <td>0.429175</td>\n",
       "      <td>-18.557679</td>\n",
       "      <td>7.069326e-77</td>\n",
       "      <td>-8.805664</td>\n",
       "      <td>-7.123328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Var     Coef.   Std.Err.          z  \\\n",
       "0                            const  0.612003  11.326093   0.054035   \n",
       "1                   Marital status -2.337882   1.068211  -2.188596   \n",
       "2                 Application mode  2.413850   0.491696   4.909231   \n",
       "3                Application order  1.094498   0.346036   3.162959   \n",
       "4                           Course  2.580834   0.412632   6.254562   \n",
       "5           Previous qualification  0.754953   0.537626   1.404234   \n",
       "6   Previous qualification (grade) -0.691580   0.329436  -2.099284   \n",
       "7                      Nationality  1.969008   4.393843   0.448129   \n",
       "8           Mother's qualification  2.059045   0.673707   3.056290   \n",
       "9           Father's qualification  0.858524   0.716629   1.198005   \n",
       "10             Mother's occupation  1.458045   0.745539   1.955692   \n",
       "11             Father's occupation  0.827030   0.817823   1.011257   \n",
       "12                       Displaced -1.906002   1.028469  -1.853242   \n",
       "13       Educational special needs  0.262401  34.876156   0.007524   \n",
       "14                          Debtor  1.282227   0.439110   2.920057   \n",
       "15         Tuition fees up to date  4.059363   0.268665  15.109368   \n",
       "16                          Gender  1.564167   0.477523   3.275586   \n",
       "17              Scholarship holder  3.080544   0.482659   6.382449   \n",
       "18               Age at enrollment  0.473789   0.410489   1.154207   \n",
       "19               Unemployment rate  0.594506   0.165763   3.586477   \n",
       "20                  Inflation rate  0.046990   0.149853   0.313576   \n",
       "21                             GDP  0.148415   0.167115   0.888105   \n",
       "22                  Curr units PC1 -6.381557   0.308080 -20.713968   \n",
       "23                  Curr units PC2 -7.964496   0.429175 -18.557679   \n",
       "\n",
       "           P>|z|     [0.025     0.975]  \n",
       "0   9.569074e-01 -21.586732  22.810738  \n",
       "1   2.862623e-02  -4.431538  -0.244227  \n",
       "2   9.143406e-07   1.450143   3.377557  \n",
       "3   1.561743e-03   0.416280   1.772717  \n",
       "4   3.986319e-10   1.772089   3.389578  \n",
       "5   1.602492e-01  -0.298775   1.808681  \n",
       "6   3.579186e-02  -1.337262  -0.045897  \n",
       "7   6.540602e-01  -6.642767  10.580783  \n",
       "8   2.240941e-03   0.738603   3.379487  \n",
       "9   2.309152e-01  -0.546042   2.263091  \n",
       "10  5.050142e-02  -0.003185   2.919274  \n",
       "11  3.118933e-01  -0.775874   2.429934  \n",
       "12  6.384775e-02  -3.921764   0.109761  \n",
       "13  9.939969e-01 -68.093609  68.618410  \n",
       "14  3.499677e-03   0.421587   2.142868  \n",
       "15  1.404807e-51   3.532789   4.585937  \n",
       "16  1.054429e-03   0.628240   2.500095  \n",
       "17  1.742783e-10   2.134550   4.026537  \n",
       "18  2.484154e-01  -0.330754   1.278333  \n",
       "19  3.351759e-04   0.269616   0.919395  \n",
       "20  7.538434e-01  -0.246716   0.340697  \n",
       "21  3.744841e-01  -0.179123   0.475954  \n",
       "22  2.591998e-95  -6.985383  -5.777732  \n",
       "23  7.069326e-77  -8.805664  -7.123328  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert features summary table to dataframe\n",
    "fit_df = (clf_fit.summary2().tables[1])\n",
    "\n",
    "#convert feature names from row index labels to column\n",
    "fit_df = fit_df.reset_index()\n",
    "fit_df = fit_df.rename(columns={'index': 'Var'})\n",
    "fit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features present a problem. Because each one-hot encoded feature has its own p-value and coefficient, we can't determine feature importance or significance just by looking at the summary statistics. We'll use a likelihood ratio test to determine significance, and simply sum the coefficients to estimate importance. The downside to this is that we must sum the absolute values of the coefficients, and thus we lose the directionality. We'd have to look at the individual coefficients to determine direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a new dataframe with the unaltered statistics for ordinal features and aggregated statistics for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364092\n",
      "         Iterations: 11\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "         Hessian evaluations: 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366372\n",
      "         Iterations: 11\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "         Hessian evaluations: 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.368172\n",
      "         Iterations: 11\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "         Hessian evaluations: 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364308\n",
      "         Iterations: 11\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364286\n",
      "         Iterations: 9\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "         Hessian evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364713\n",
      "         Iterations: 12\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.363871\n",
      "         Iterations: 12\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364127\n",
      "         Iterations: 12\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.363764\n",
      "         Iterations: 12\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.363961\n",
      "         Iterations: 12\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.363711\n",
      "         Iterations: 12\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364682\n",
      "         Iterations: 12\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394845\n",
      "         Iterations: 12\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364899\n",
      "         Iterations: 13\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "         Hessian evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.368682\n",
      "         Iterations: 9\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "         Hessian evaluations: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Abs_coef</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marital status</td>\n",
       "      <td>2.337882</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>2.413850</td>\n",
       "      <td>8.814488e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Course</td>\n",
       "      <td>2.580834</td>\n",
       "      <td>2.326096e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Previous qualification</td>\n",
       "      <td>0.691580</td>\n",
       "      <td>4.743286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nationality</td>\n",
       "      <td>1.969008</td>\n",
       "      <td>2.541112e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mother's qualification</td>\n",
       "      <td>2.059045</td>\n",
       "      <td>2.422199e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Father's qualification</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mother's occupation</td>\n",
       "      <td>1.458045</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Father's occupation</td>\n",
       "      <td>0.827030</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Displaced</td>\n",
       "      <td>1.906002</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Educational special needs</td>\n",
       "      <td>0.262401</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>1.282227</td>\n",
       "      <td>2.836399e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>4.059363</td>\n",
       "      <td>4.884943e-61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.564167</td>\n",
       "      <td>9.524026e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>3.080544</td>\n",
       "      <td>2.305309e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Var  Abs_coef             p\n",
       "0              Marital status  2.337882  1.000000e+00\n",
       "1            Application mode  2.413850  8.814488e-06\n",
       "2                      Course  2.580834  2.326096e-09\n",
       "3      Previous qualification  0.691580  4.743286e-01\n",
       "4                 Nationality  1.969008  2.541112e-01\n",
       "5      Mother's qualification  2.059045  2.422199e-02\n",
       "6      Father's qualification  0.858524  1.000000e+00\n",
       "7         Mother's occupation  1.458045  1.000000e+00\n",
       "8         Father's occupation  0.827030  1.000000e+00\n",
       "9                   Displaced  1.906002  1.000000e+00\n",
       "10  Educational special needs  0.262401  1.000000e+00\n",
       "11                     Debtor  1.282227  2.836399e-02\n",
       "12    Tuition fees up to date  4.059363  4.884943e-61\n",
       "13                     Gender  1.564167  9.524026e-03\n",
       "14         Scholarship holder  3.080544  2.305309e-10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can't get the likelihood ratio tests included in statsmodels to work, so I'll write my own \n",
    "def lr_test(reduced_model):\n",
    "    import scipy.stats as stats\n",
    "\n",
    "    # get log likelihoods for each model\n",
    "    ll_full = clf_fit.llf\n",
    "    ll_reduced = reduced_model.llf\n",
    "\n",
    "    lr_stat = -2 * (ll_reduced - ll_full) # test statistic\n",
    "    df_diff = clf.df_model - reduced_model.df_model  # difference in degrees of freedom between models\n",
    "    lr_p_value = stats.chi2.sf(lr_stat, df_diff) # p-value\n",
    "\n",
    "    return lr_p_value\n",
    "\n",
    "coefs = []\n",
    "p = []\n",
    "oh_var_list = fit_df['Var'].to_list()\n",
    "\n",
    "for var1 in nominal:\n",
    "    sum_abs = 0\n",
    "    to_drop = []\n",
    "\n",
    "    for var2 in oh_var_list:\n",
    "        if var1 in var2:\n",
    "            sum_abs =+ float(abs(fit_df[fit_df['Var']==var2]['Coef.']).values) \n",
    "            to_drop.append(var2)\n",
    "\n",
    "    coefs.append(sum_abs)\n",
    "\n",
    "    reduced_model = sm.Logit(y, X_intp.drop(columns=to_drop)).fit(method='ncg')\n",
    "    p.append(lr_test(reduced_model))\n",
    "    \n",
    "cat_df = pd.DataFrame({'Var': nominal,\n",
    "                       'Abs_coef': coefs,\n",
    "                       'p': p})\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find all the features with non-significant p-values so that we can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with non-significant coefficients:\n",
      "\n",
      "['Age at enrollment', 'Inflation rate', 'GDP', 'Marital status', 'Previous qualification', 'Nationality', \"Father's qualification\", \"Mother's occupation\", \"Father's occupation\", 'Displaced', 'Educational special needs']\n"
     ]
    }
   ],
   "source": [
    "ordinal = [var for var in X.columns if var not in nominal]\n",
    "not_sig = fit_df[(fit_df['P>|z|'] > 0.05) & (fit_df['Var'].isin(ordinal))]['Var'].tolist() + cat_df[cat_df['p'] > 0.05]['Var'].tolist()\n",
    "\n",
    "print('Features with non-significant coefficients:\\n')\n",
    "print(not_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dataframe containing all the features and their importances so that we can plot them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Coef</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Application order</td>\n",
       "      <td>1.094498</td>\n",
       "      <td>1.561743e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>-0.691580</td>\n",
       "      <td>3.579186e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>0.594506</td>\n",
       "      <td>3.351759e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Curr units PC1</td>\n",
       "      <td>-6.381557</td>\n",
       "      <td>2.591998e-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Curr units PC2</td>\n",
       "      <td>-7.964496</td>\n",
       "      <td>7.069326e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>2.413850</td>\n",
       "      <td>8.814488e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Course</td>\n",
       "      <td>2.580834</td>\n",
       "      <td>2.326096e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mother's qualification</td>\n",
       "      <td>2.059045</td>\n",
       "      <td>2.422199e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>1.282227</td>\n",
       "      <td>2.836399e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>4.059363</td>\n",
       "      <td>4.884943e-61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.564167</td>\n",
       "      <td>9.524026e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>3.080544</td>\n",
       "      <td>2.305309e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Var      Coef             p\n",
       "3                Application order  1.094498  1.561743e-03\n",
       "6   Previous qualification (grade) -0.691580  3.579186e-02\n",
       "19               Unemployment rate  0.594506  3.351759e-04\n",
       "22                  Curr units PC1 -6.381557  2.591998e-95\n",
       "23                  Curr units PC2 -7.964496  7.069326e-77\n",
       "1                 Application mode  2.413850  8.814488e-06\n",
       "2                           Course  2.580834  2.326096e-09\n",
       "5           Mother's qualification  2.059045  2.422199e-02\n",
       "11                          Debtor  1.282227  2.836399e-02\n",
       "12         Tuition fees up to date  4.059363  4.884943e-61\n",
       "13                          Gender  1.564167  9.524026e-03\n",
       "14              Scholarship holder  3.080544  2.305309e-10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the columns match between the dataframes\n",
    "fit_df = fit_df.drop(['Std.Err.', 'z', '[0.025', '0.975]'], axis=1)\n",
    "fit_df = fit_df.rename(columns={'P>|z|': 'p', 'Coef.': 'Coef'})\n",
    "cat_df = cat_df.rename(columns={'Abs_coef': 'Coef'})\n",
    "\n",
    "# concatenate the dataframes, filtering out non-significant features\n",
    "sig_df = pd.concat([fit_df[(fit_df['p'] <= 0.05) & (fit_df['Var'].isin(ordinal))], cat_df[cat_df['p'] <= 0.05]], axis=0)\n",
    "sig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x22031586dc0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sort dataframe\n",
    "sig_df = sig_df.sort_values(by='Coef', ascending=False, key=abs)\n",
    "\n",
    "# plot coefficients\n",
    "g = sns.barplot(data=sig_df, x='Var', y='Coef')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "g.set_xlabel('Variable')\n",
    "g.set_ylabel('Importance')\n",
    "g.axhline(y=0, color='black', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constant coefficient is 9.85, which is about equal to the most important features. This means our model's baseline probability is not 50%, and the predictive model should have a strong bias toward one error type over the other.\n",
    "\n",
    "The most important features are:\n",
    "1. Curr units PC2\n",
    "2. Curr Units PC1\n",
    "3. Tuition fees up to date\n",
    "4. Age at enrollment\n",
    "5. Mother's qualification\n",
    "6. Unemployment rate\n",
    "7. Scholarship holder\n",
    "8. Course\n",
    "9. Debtor\n",
    "10. Father's occupation\n",
    "11. Gender\n",
    "\n",
    "Mother's occupation has a statistically significant coefficient, but the actual magnitude is negligable. \n",
    "\n",
    "Even though some of these features have small coefficients, that doesn't mean they aren't useful in a predictive model. Even including the non-significant features may improve the model's metrics. This analysis is meant to help us understand which factors are important to examine in the student population. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Curricular units:<br>\n",
    "This is by far the most important factor. There is a very strong inverse relationship between number of curricular units and chance of graduating. \n",
    "\n",
    "Tuition fees up to date:<br>\n",
    "Predictably, those struggling to pay tuition are likely to dropout. This is the second most important factor. \n",
    "\n",
    "Age at enrollment:<br>\n",
    "Older individuals are more likely to dropout.\n",
    "\n",
    "Scholarship holder:<br>\n",
    "Students with scholarships are less likely to dropout.\n",
    "\n",
    "Debtor:<br>\n",
    "Debtors are slightly more likely to dropout. \n",
    "\n",
    "Gender:<br>\n",
    "Males are more likely to dropout (males are encoded as 0). This may be because males often aspire for the trades and the military, whereas females have few obvious pathways outside of education that aren't male dominated. This means that preventing male students from dropping out may be a matter of career counseling, but more investigation is needed to determine that.\n",
    "\n",
    "Course:<br>\n",
    "Students majoring in Animation and Multimedia Design are more likely to dropout than the other majors in the sample. This requires more analysis, since the sample included only 17 majors, some of which are probably not very popular (such as equinculture).\n",
    "\n",
    "Marital status:<br>\n",
    "Married students are slightly more likely to dropout, but not enough to be concerning. \n",
    "\n",
    "Mother's occupation:<br>\n",
    "Mother's occupation has more effect than father's occupation, with different categories affecting the probability of dropping out in different directions. Most of these effects are relatively small. The exception is for cleaning workers, whose children are much more likely to dropout than any other occupation category. The importance of the feature as a whole mainly comes from this one category. \n",
    "\n",
    "Father's occupation:<br>\n",
    "Father's occupation doesn't have much relationship with dropping out. Only 2 of the 12 categories have a very small effect. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

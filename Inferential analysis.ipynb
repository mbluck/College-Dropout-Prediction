{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discovered during EDA, there is high multicolinearity in our feature set. We'll reference the association heatmaps in the EDA notebook. \n",
    "\n",
    "To begin, we'll address the redundancy between 'Admission grade' and 'Previous qualification (grade)' by removing whichever one has lower mutual information with the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission grade: [0.02852458]\n",
      "Previous qualification (grade): [0.0357418]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('LogReg/X.csv')\n",
    "y = pd.read_csv('LogReg/y.csv')\n",
    "\n",
    "y_np = y.to_numpy()\n",
    "y_np = y_np.ravel()\n",
    "\n",
    "ag = mutual_info_classif(X['Admission grade'].to_frame(), y_np, discrete_features=False, random_state=1)\n",
    "pqg = mutual_info_classif(X['Previous qualification (grade)'].to_frame(), y_np, discrete_features=False, random_state=1)\n",
    "\n",
    "print(f'Admission grade: {ag}\\nPrevious qualification (grade): {pqg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove 'Admission grade'.\n",
    "\n",
    "We'll also remove 'International' because it's completely redundant with 'Nationality' but provides less information.\n",
    "\n",
    "Next, we'll address the fact that 'Course' and 'Daytime/evening attendance' are one for one associated. We'll remove 'Daytime/evening attendance' because it's redundant with 'Course', which contains more information.\n",
    "\n",
    "Curricular units (enrolled), for both 1st and 2nd semesters, are highly associated with 'Course'. However, we should be careful about removing either since they provide very different types of information. Let's compare their relatinships to the target using mutual information. We can't compare VIF scores since one feature is categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: [0.03455513]\n",
      "Curricular units 1st sem (enrolled): [0.02378636]\n"
     ]
    }
   ],
   "source": [
    "# COMPARE MUTUAL INFORMATION\n",
    "c = mutual_info_classif(X['Course'].to_frame(), y_np, discrete_features=True, random_state=1)\n",
    "cu = mutual_info_classif(X['Curricular units 1st sem (enrolled)'].to_frame(), y_np, discrete_features=False, random_state=1)\n",
    "\n",
    "print(f'Course: {c}\\nCurricular units 1st sem (enrolled): {cu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE REDUNDANT FEATURES\n",
    "\n",
    "X = X.drop(['Admission grade', 'Daytime/evening attendance', 'International'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still not clear if it's suitable to remove one or the other. Let's keep both for now and choose one based on model performance later.\n",
    "\n",
    "Now we need to address the high multicolinearity among all the features measuring curricular units. Let's try using PCA.<br>\n",
    "First, we'll try PCA using all the features. This probably won't yield good results as most of the features aren't correlated amongst each other. Then, we'll try using subset PCA, wherein only the curricular unit features are transformed and the other features are left unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:\n",
      "[9.99840289e-01 7.80459674e-05 4.11694210e-05]\n",
      "\n",
      "Curr Units features:\n",
      "[0.64980168 0.25016538 0.05229662]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "curr_units = [\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)'\n",
    "]\n",
    "\n",
    "# ALL FEATURES\n",
    "pca_all = PCA(n_components=3)\n",
    "pca_all.fit(X)\n",
    "\n",
    "# CURR UNITS FEATURES\n",
    "pca_cu = PCA(n_components=3)\n",
    "pca_cu.fit(X[curr_units])\n",
    "\n",
    "print(f'All features:\\n{pca_all.explained_variance_ratio_}\\n\\nCurr Units features:\\n{pca_cu.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components of pca_all explain almost no variance, whereas the first two components of pca_cu explain 90% of it. We'll replace all the curricular unit features with these two components. This also resolves the 'Curricular units (enrolled)' vs 'Course' issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE CURR UNITS FEATURES WITH PRINCIPLE COMPONENTS\n",
    "\n",
    "pca_cu = PCA(n_components=2)\n",
    "transformed = pca_cu.fit_transform(X[curr_units])\n",
    "\n",
    "pca_df = pd.DataFrame(transformed, columns=[f'Curr units PC{i+1}' for i in range(transformed.shape[1])])\n",
    "X = X.drop(curr_units, axis=1)\n",
    "X = pd.concat([X, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marital status', 'Application mode', 'Application order', 'Course',\n",
       "       'Previous qualification', 'Previous qualification (grade)',\n",
       "       'Nationality', 'Mother's qualification', 'Father's qualification',\n",
       "       'Mother's occupation', 'Father's occupation', 'Displaced',\n",
       "       'Educational special needs', 'Debtor', 'Tuition fees up to date',\n",
       "       'Gender', 'Scholarship holder', 'Age at enrollment',\n",
       "       'Unemployment rate', 'Inflation rate', 'GDP', 'Curr units PC1',\n",
       "       'Curr units PC2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we model, let's define functions for scaling and one-hot encoding the data that will handle the combination of categorical and numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Function to scale data without altering nominal features.\n",
    "Takes 'df' (a dataframe) and 'nominal' (a list of nominal feature names).\n",
    "Returns the transformed dataframe. \n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale(df, nominal):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    for var in df.columns:\n",
    "            \n",
    "        if var not in nominal:\n",
    "            raw = df[var].to_numpy()\n",
    "            raw = raw.reshape(-1, 1)\n",
    "\n",
    "            scaler.fit(raw)\n",
    "            scaled = scaler.transform(raw)\n",
    "            df[var] = scaled\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Function to one-hot encode data without altering non-nominal features.\n",
    "Takes 'df' (a dataframe) and 'nominal' (a list of nominal feature names).\n",
    "Returns the transformed dataframe.\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot(df, nominal):\n",
    "\n",
    "    # initialize encoder object\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist', drop='first')\n",
    "\n",
    "    # subset data\n",
    "    df = df[nominal]\n",
    "\n",
    "    # fit\n",
    "    fit = encoder.fit(df)\n",
    "    \n",
    "    # transform\n",
    "    encoded = encoder.transform(df)\n",
    "\n",
    "    # convert result to df\n",
    "    one_hot_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(nominal))\n",
    "\n",
    "    # add results to full data\n",
    "    data_one_hot = pd.concat([df.reset_index(drop=True), \n",
    "                              one_hot_df.reset_index(drop=True)], \n",
    "                              axis=1)\n",
    "\n",
    "    # drop original nominal columns\n",
    "    data_one_hot = data_one_hot.drop(nominal, axis=1)\n",
    "\n",
    "    return data_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.361282\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   No. Observations:                 4424\n",
      "Model:                          Logit   Df Residuals:                     4400\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Mon, 21 Oct 2024   Pseudo R-squ.:                  0.4245\n",
      "Time:                        20:57:14   Log-Likelihood:                -1598.3\n",
      "converged:                       True   LL-Null:                       -2777.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "const                             -5.8443      0.991     -5.899      0.000      -7.786      -3.902\n",
      "Marital status                    -0.1647      0.089     -1.849      0.064      -0.339       0.010\n",
      "Application mode                   0.0041      0.003      1.222      0.222      -0.002       0.011\n",
      "Application order                  0.0345      0.039      0.877      0.380      -0.043       0.111\n",
      "Course                             0.0003   2.55e-05     10.934      0.000       0.000       0.000\n",
      "Previous qualification            -0.0034      0.005     -0.699      0.484      -0.013       0.006\n",
      "Previous qualification (grade)    -0.0028      0.004     -0.791      0.429      -0.010       0.004\n",
      "Nationality                       -0.4927      0.186     -2.643      0.008      -0.858      -0.127\n",
      "Mother's qualification             0.0403      0.026      1.534      0.125      -0.011       0.092\n",
      "Father's qualification             0.0307      0.027      1.134      0.257      -0.022       0.084\n",
      "Mother's occupation                0.0143      0.019      0.768      0.443      -0.022       0.051\n",
      "Father's occupation                0.0016      0.016      0.101      0.920      -0.030       0.034\n",
      "Displaced                          0.2827      0.106      2.678      0.007       0.076       0.490\n",
      "Educational special needs          0.2406      0.394      0.611      0.541      -0.531       1.013\n",
      "Debtor                             0.5292      0.150      3.536      0.000       0.236       0.823\n",
      "Tuition fees up to date           -2.5276      0.168    -15.040      0.000      -2.857      -2.198\n",
      "Gender                             0.4661      0.095      4.921      0.000       0.280       0.652\n",
      "Scholarship holder                -0.8178      0.128     -6.368      0.000      -1.069      -0.566\n",
      "Age at enrollment                  1.5454      0.234      6.599      0.000       1.086       2.004\n",
      "Unemployment rate                  0.0356      0.018      1.946      0.052      -0.000       0.072\n",
      "Inflation rate                     0.0252      0.033      0.766      0.443      -0.039       0.090\n",
      "GDP                                0.0059      0.022      0.265      0.791      -0.037       0.049\n",
      "Curr units PC1                    -0.1940      0.010    -20.406      0.000      -0.213      -0.175\n",
      "Curr units PC2                    -0.2580      0.014    -19.015      0.000      -0.285      -0.231\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# add intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# fit\n",
    "clf = sm.Logit(y, X)\n",
    "clf_fit = clf.fit()\n",
    "\n",
    "# summary stats\n",
    "print(clf_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err.</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>-5.844276</td>\n",
       "      <td>0.990786</td>\n",
       "      <td>-5.898624</td>\n",
       "      <td>3.665456e-09</td>\n",
       "      <td>-7.786181</td>\n",
       "      <td>-3.902370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marital status</td>\n",
       "      <td>-0.164703</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>-1.848824</td>\n",
       "      <td>6.448325e-02</td>\n",
       "      <td>-0.339307</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>1.221818</td>\n",
       "      <td>2.217766e-01</td>\n",
       "      <td>-0.002498</td>\n",
       "      <td>0.010768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Application order</td>\n",
       "      <td>0.034455</td>\n",
       "      <td>0.039267</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>3.802417e-01</td>\n",
       "      <td>-0.042507</td>\n",
       "      <td>0.111417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Course</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>10.933905</td>\n",
       "      <td>7.935830e-28</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Previous qualification</td>\n",
       "      <td>-0.003382</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>-0.699139</td>\n",
       "      <td>4.844652e-01</td>\n",
       "      <td>-0.012861</td>\n",
       "      <td>0.006098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>-0.791462</td>\n",
       "      <td>4.286742e-01</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nationality</td>\n",
       "      <td>-0.492743</td>\n",
       "      <td>0.186402</td>\n",
       "      <td>-2.643435</td>\n",
       "      <td>8.206945e-03</td>\n",
       "      <td>-0.858085</td>\n",
       "      <td>-0.127401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mother's qualification</td>\n",
       "      <td>0.040299</td>\n",
       "      <td>0.026268</td>\n",
       "      <td>1.534138</td>\n",
       "      <td>1.249957e-01</td>\n",
       "      <td>-0.011186</td>\n",
       "      <td>0.091784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Father's qualification</td>\n",
       "      <td>0.030669</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>1.134162</td>\n",
       "      <td>2.567266e-01</td>\n",
       "      <td>-0.022331</td>\n",
       "      <td>0.083670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mother's occupation</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>0.018655</td>\n",
       "      <td>0.767776</td>\n",
       "      <td>4.426203e-01</td>\n",
       "      <td>-0.022240</td>\n",
       "      <td>0.050886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Father's occupation</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.101017</td>\n",
       "      <td>9.195367e-01</td>\n",
       "      <td>-0.030333</td>\n",
       "      <td>0.033629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Displaced</td>\n",
       "      <td>0.282736</td>\n",
       "      <td>0.105589</td>\n",
       "      <td>2.677712</td>\n",
       "      <td>7.412697e-03</td>\n",
       "      <td>0.075786</td>\n",
       "      <td>0.489687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Educational special needs</td>\n",
       "      <td>0.240590</td>\n",
       "      <td>0.393852</td>\n",
       "      <td>0.610863</td>\n",
       "      <td>5.412901e-01</td>\n",
       "      <td>-0.531347</td>\n",
       "      <td>1.012526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>0.529235</td>\n",
       "      <td>0.149676</td>\n",
       "      <td>3.535872</td>\n",
       "      <td>4.064309e-04</td>\n",
       "      <td>0.235875</td>\n",
       "      <td>0.822594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>-2.527621</td>\n",
       "      <td>0.168062</td>\n",
       "      <td>-15.039768</td>\n",
       "      <td>4.029573e-51</td>\n",
       "      <td>-2.857017</td>\n",
       "      <td>-2.198224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.466074</td>\n",
       "      <td>0.094710</td>\n",
       "      <td>4.921085</td>\n",
       "      <td>8.606583e-07</td>\n",
       "      <td>0.280447</td>\n",
       "      <td>0.651701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>-0.817783</td>\n",
       "      <td>0.128423</td>\n",
       "      <td>-6.367872</td>\n",
       "      <td>1.916693e-10</td>\n",
       "      <td>-1.069488</td>\n",
       "      <td>-0.566078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>1.545362</td>\n",
       "      <td>0.234169</td>\n",
       "      <td>6.599343</td>\n",
       "      <td>4.129838e-11</td>\n",
       "      <td>1.086399</td>\n",
       "      <td>2.004325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>0.035641</td>\n",
       "      <td>0.018311</td>\n",
       "      <td>1.946396</td>\n",
       "      <td>5.160718e-02</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.071531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Inflation rate</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>0.032881</td>\n",
       "      <td>0.766431</td>\n",
       "      <td>4.434197e-01</td>\n",
       "      <td>-0.039245</td>\n",
       "      <td>0.089647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GDP</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.022087</td>\n",
       "      <td>0.265332</td>\n",
       "      <td>7.907533e-01</td>\n",
       "      <td>-0.037430</td>\n",
       "      <td>0.049151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Curr units PC1</td>\n",
       "      <td>-0.193987</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>-20.405957</td>\n",
       "      <td>1.480361e-92</td>\n",
       "      <td>-0.212619</td>\n",
       "      <td>-0.175355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Curr units PC2</td>\n",
       "      <td>-0.258042</td>\n",
       "      <td>0.013570</td>\n",
       "      <td>-19.015188</td>\n",
       "      <td>1.276777e-80</td>\n",
       "      <td>-0.284640</td>\n",
       "      <td>-0.231445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Var     Coef.  Std.Err.          z  \\\n",
       "0                            const -5.844276  0.990786  -5.898624   \n",
       "1                   Marital status -0.164703  0.089085  -1.848824   \n",
       "2                 Application mode  0.004135  0.003384   1.221818   \n",
       "3                Application order  0.034455  0.039267   0.877451   \n",
       "4                           Course  0.000278  0.000025  10.933905   \n",
       "5           Previous qualification -0.003382  0.004837  -0.699139   \n",
       "6   Previous qualification (grade) -0.002806  0.003545  -0.791462   \n",
       "7                      Nationality -0.492743  0.186402  -2.643435   \n",
       "8           Mother's qualification  0.040299  0.026268   1.534138   \n",
       "9           Father's qualification  0.030669  0.027041   1.134162   \n",
       "10             Mother's occupation  0.014323  0.018655   0.767776   \n",
       "11             Father's occupation  0.001648  0.016317   0.101017   \n",
       "12                       Displaced  0.282736  0.105589   2.677712   \n",
       "13       Educational special needs  0.240590  0.393852   0.610863   \n",
       "14                          Debtor  0.529235  0.149676   3.535872   \n",
       "15         Tuition fees up to date -2.527621  0.168062 -15.039768   \n",
       "16                          Gender  0.466074  0.094710   4.921085   \n",
       "17              Scholarship holder -0.817783  0.128423  -6.367872   \n",
       "18               Age at enrollment  1.545362  0.234169   6.599343   \n",
       "19               Unemployment rate  0.035641  0.018311   1.946396   \n",
       "20                  Inflation rate  0.025201  0.032881   0.766431   \n",
       "21                             GDP  0.005860  0.022087   0.265332   \n",
       "22                  Curr units PC1 -0.193987  0.009506 -20.405957   \n",
       "23                  Curr units PC2 -0.258042  0.013570 -19.015188   \n",
       "\n",
       "           P>|z|    [0.025    0.975]  \n",
       "0   3.665456e-09 -7.786181 -3.902370  \n",
       "1   6.448325e-02 -0.339307  0.009901  \n",
       "2   2.217766e-01 -0.002498  0.010768  \n",
       "3   3.802417e-01 -0.042507  0.111417  \n",
       "4   7.935830e-28  0.000229  0.000328  \n",
       "5   4.844652e-01 -0.012861  0.006098  \n",
       "6   4.286742e-01 -0.009755  0.004143  \n",
       "7   8.206945e-03 -0.858085 -0.127401  \n",
       "8   1.249957e-01 -0.011186  0.091784  \n",
       "9   2.567266e-01 -0.022331  0.083670  \n",
       "10  4.426203e-01 -0.022240  0.050886  \n",
       "11  9.195367e-01 -0.030333  0.033629  \n",
       "12  7.412697e-03  0.075786  0.489687  \n",
       "13  5.412901e-01 -0.531347  1.012526  \n",
       "14  4.064309e-04  0.235875  0.822594  \n",
       "15  4.029573e-51 -2.857017 -2.198224  \n",
       "16  8.606583e-07  0.280447  0.651701  \n",
       "17  1.916693e-10 -1.069488 -0.566078  \n",
       "18  4.129838e-11  1.086399  2.004325  \n",
       "19  5.160718e-02 -0.000248  0.071531  \n",
       "20  4.434197e-01 -0.039245  0.089647  \n",
       "21  7.907533e-01 -0.037430  0.049151  \n",
       "22  1.480361e-92 -0.212619 -0.175355  \n",
       "23  1.276777e-80 -0.284640 -0.231445  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert features summary table to dataframe\n",
    "fit_df = (clf_fit.summary2().tables[1])\n",
    "\n",
    "#convert feature names from row index labels to column\n",
    "fit_df = fit_df.reset_index()\n",
    "fit_df = fit_df.rename(columns={'index': 'Var'})\n",
    "fit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with non-significant coefficients:\n",
      "\n",
      "['Marital status', 'Application mode', 'Application order', 'Previous qualification', 'Previous qualification (grade)', \"Mother's qualification\", \"Father's qualification\", \"Mother's occupation\", \"Father's occupation\", 'Educational special needs', 'Unemployment rate', 'Inflation rate', 'GDP']\n"
     ]
    }
   ],
   "source": [
    "not_sig = fit_df[fit_df['P>|z|'] > 0.05]['Var'].tolist()\n",
    "\n",
    "print('Features with non-significant coefficients:\\n')\n",
    "print(not_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.363400\n",
      "         Iterations 7\n",
      "Features with non-significant coefficients:\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# remove non-significant features and repeat the modeling\n",
    "\n",
    "# remove features\n",
    "X = X.drop(not_sig, axis=1)\n",
    "\n",
    "# fit\n",
    "clf = sm.Logit(y, X)\n",
    "clf_fit = clf.fit()\n",
    "\n",
    "# convert features summary table to dataframe\n",
    "fit_df = (clf_fit.summary2().tables[1])\n",
    "\n",
    "#convert feature names from row index labels to column\n",
    "fit_df = fit_df.reset_index()\n",
    "fit_df = fit_df.rename(columns={'index': 'Var'})\n",
    "\n",
    "not_sig = fit_df[fit_df['P>|z|'] > 0.05]['Var'].tolist()\n",
    "\n",
    "print('Features with non-significant coefficients:\\n')\n",
    "print(not_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features now have a statistically significant relationship to the target. Let's plot their coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x20d93494c70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sort dataframe\n",
    "fit_df = fit_df.sort_values(by='Coef.', ascending=False, key=abs)\n",
    "\n",
    "# plot coefficients\n",
    "g = sns.barplot(data=fit_df, x='Var', y='Coef.')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "g.axhline(y=0, color='black', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constant coefficient is HUGE. This means our predictive model is going to predict false negatives far more often than false positives, which is not what we want. We'll probably have to tune the decision threshold to deal with this.\n",
    "\n",
    "The most important features are:\n",
    "1. Tuition fees up to date\n",
    "2. Age at enrollment\n",
    "3. Scholarship holder\n",
    "4. Debtor\n",
    "5. Nationality\n",
    "6. Displaced\n",
    "7. Curr units PC2\n",
    "8. Curr units PC1\n",
    "\n",
    "Even though some of these features have small coefficients, that doesn't mean they aren't useful in a predictive model. Even including the non-significant features may improve the model's metrics. This analysis is meant to help us understand which factors are important to examine in the student population. <br>\n",
    "\n",
    "Given that female is encoded as 0 and male is 1, males are more likely to dropout. This may be because males often aspire for the trades and the military, whereas females have few obvious pathways outside of education that aren't male dominated. This means that preventing male students from dropping out may be a matter of career counseling more so than academic counseling, but more investigation is needed to determine that.<br>\n",
    "Older individuals are also more likely to dropout. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Tuition fees up to date:<br>\n",
    "Predictably, those struggling to pay tuition are likely to dropout. This is the single most important factor. \n",
    "\n",
    "Age at enrollment:<br>\n",
    "Older individuals are more likely to dropout.\n",
    "\n",
    "Scholarship holder:<br>\n",
    "Students with scholarships are less likely to dropout.\n",
    "\n",
    "Debtor:<br>\n",
    "Once again, those with financial struggles are more likely to dropout.\n",
    "\n",
    "Gender:<br>\n",
    "Males are more likely to dropout. This may be because males often aspire for the trades and the military, whereas females have few obvious pathways outside of education that aren't male dominated. This means that preventing male students from dropping out may be a matter of career counseling, but more investigation is needed to determine that.\n",
    "\n",
    "Nationality:<br>\n",
    "International students are less likely to dropout.\n",
    "\n",
    "Displaced:<br>\n",
    "Displaced students are more likely to dropout, though not as much as I'd expect.\n",
    "\n",
    "Curricular units:<br>\n",
    "Those with fewer curricular units are more likely to dropout, but not by a lot.\n",
    "\n",
    "Course:<br>\n",
    "While course does have an impact on a student's chance of dropping out, it's very small. Course should not be a matter of concern. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

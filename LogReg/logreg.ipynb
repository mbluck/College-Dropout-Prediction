{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_csv('LogReg/X.csv')\n",
    "y = pd.read_csv('LogReg/y.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions that scale and one-hot encode the data. We will use the scaled data for everything in this notebook file, but only use one-hot encoding for fitting logistic regression and NOT for anything tree based such as boruta and mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale(df, nominal):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    for var in df.columns:\n",
    "            \n",
    "        if var not in nominal:\n",
    "            raw = df[var].to_numpy()\n",
    "            raw = raw.reshape(-1, 1)\n",
    "\n",
    "            scaler.fit(raw)\n",
    "            scaled = scaler.transform(raw)\n",
    "            df[var] = scaled\n",
    "\n",
    "    return df\n",
    "\n",
    "#since we'll use the scaled data for everything, scale X now\n",
    "\n",
    "nominal = [\n",
    "            'Marital status',      \n",
    "            'Application mode',          \n",
    "            'Application order',         \n",
    "            'Course',                    \n",
    "            'Daytime/evening attendance',\n",
    "            'Previous qualification',    \n",
    "            'Nationality',               \n",
    "            \"Mother's qualification\",    \n",
    "            \"Father's qualification\",    \n",
    "            \"Mother's occupation\",       \n",
    "            \"Father's occupation\",       \n",
    "            'Displaced',              \n",
    "            'Educational special needs', \n",
    "            'Debtor',                    \n",
    "            'Tuition fees up to date',   \n",
    "            'Gender',                                              \n",
    "            'Scholarship holder',                                  \n",
    "            'International'\n",
    "            ]\n",
    "\n",
    "X = scale(X, nominal)\n",
    "X_train = scale(X_train, nominal)\n",
    "X_test = scale(X_test, nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot(transform_df, fit_df, nominal):\n",
    "# requires passing a list of the nominal columns \n",
    "# fit_df is the dataframe to fit the encoder onto\n",
    "# transform_df is the dataframe to transform with the encoder\n",
    "\n",
    "    # initialize encoder object\n",
    "    # use 'infrequent_if_exist' for unseen categories since some features are very sparse\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist', drop='first')\n",
    "\n",
    "    # fit\n",
    "    fit = encoder.fit(fit_df[nominal])\n",
    "    \n",
    "    # transform\n",
    "    encoded = encoder.transform(transform_df[nominal])\n",
    "\n",
    "    # convert result to df\n",
    "    one_hot_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(nominal))\n",
    "\n",
    "    # add results to full data\n",
    "    data_one_hot = pd.concat([transform_df.reset_index(drop=True), \n",
    "                              one_hot_df.reset_index(drop=True)], \n",
    "                              axis=1)\n",
    "\n",
    "    # drop original nominal columns\n",
    "    data_one_hot = data_one_hot.drop(nominal, axis=1)\n",
    "\n",
    "    return data_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for feature selection is not straightforward due to the mix of nominal and interval features. The need to encode the nominal features eliminates wrapper methods. In the case of one-hot/dummy encoding, they will eliminate individual levels from a feature. In the case of label encoding, the features will be misinterpreted as ordinal. Tree-based algorithms are likely the best approach out of all the supervised methods. We can try an ensemble of different methods and compare performance. In the event that none are the clear winner, we can use them in a voting selector. <br>\n",
    "\n",
    "These are the feature selection methods we'll use:<br>\n",
    "\n",
    "**Boruta**<br>\n",
    "This is a highly successful tree-based algorithm that will likely do better than a simple filter method and can be used for any classification model. <br>\n",
    "\n",
    "**Mutual information**<br>\n",
    "We can filter by mutual information since it's able to capture any kind of dependency. <br>\n",
    "\n",
    "**Recursive feature elimination**<br>\n",
    "As discussed, our nominal data is probably an issue for this method, but there's no harm in trying it. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Application mode',\n",
       " 'Course',\n",
       " 'Previous qualification (grade)',\n",
       " \"Mother's occupation\",\n",
       " \"Father's occupation\",\n",
       " 'Admission grade',\n",
       " 'Debtor',\n",
       " 'Tuition fees up to date',\n",
       " 'Gender',\n",
       " 'Scholarship holder',\n",
       " 'Age at enrollment',\n",
       " 'Curricular units 1st sem (enrolled)',\n",
       " 'Curricular units 1st sem (evaluations)',\n",
       " 'Curricular units 1st sem (approved)',\n",
       " 'Curricular units 1st sem (grade)',\n",
       " 'Curricular units 2nd sem (enrolled)',\n",
       " 'Curricular units 2nd sem (evaluations)',\n",
       " 'Curricular units 2nd sem (approved)',\n",
       " 'Curricular units 2nd sem (grade)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BORUTA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# BorutyPy expects numpy arrays\n",
    "X = X_train.values\n",
    "y = y_train.values\n",
    "y = y.ravel()\n",
    "\n",
    "# fit random forest classifier\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight={0:0.7, 1:0.3}, max_depth=5)\n",
    "rf.fit(X,y)\n",
    "\n",
    "# initialize and fit Boruta selector\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# display selected features\n",
    "boruta_subset = [feature for feature, keep in zip(X_train.columns, feat_selector.support_) if keep]\n",
    "boruta_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [0, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boruta accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# BORUTA TEST\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "X_train_boruta = X_train[boruta_subset]\n",
    "X_test_boruta = X_test[boruta_subset]\n",
    "\n",
    "# one-hot encode data\n",
    "nominal = ['Application mode', 'Course', \"Mother's occupation\", \"Father's occupation\", 'Debtor', 'Tuition fees up to date', 'Gender', 'Scholarship holder']\n",
    "X_train_boruta_oh = one_hot(X_train_boruta, X_train_boruta, nominal)\n",
    "X_test_boruta_oh = one_hot(X_test_boruta, X_train_boruta, nominal)\n",
    "\n",
    "# fit logistic regression to get accuracy score\n",
    "clf = LogisticRegressionCV(random_state=1, class_weight={0:0.7, 1:0.3}, solver='newton-cholesky').fit(X_train_boruta_oh, y)\n",
    "score = clf.score(X_test_boruta_oh, y_test)\n",
    "print(f'Boruta accuracy: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Application mode', 'Course', 'Previous qualification',\n",
       "       'Previous qualification (grade)', 'Mother's qualification',\n",
       "       'Father's qualification', 'Father's occupation', 'Debtor',\n",
       "       'Tuition fees up to date', 'Scholarship holder', 'Age at enrollment',\n",
       "       'Curricular units 1st sem (enrolled)',\n",
       "       'Curricular units 1st sem (evaluations)',\n",
       "       'Curricular units 1st sem (approved)',\n",
       "       'Curricular units 1st sem (grade)',\n",
       "       'Curricular units 2nd sem (enrolled)',\n",
       "       'Curricular units 2nd sem (evaluations)',\n",
       "       'Curricular units 2nd sem (approved)',\n",
       "       'Curricular units 2nd sem (grade)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MUTUAL INFORMATION\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# SelectKBest expects numpy arrays\n",
    "X = X_train.values\n",
    "y = y_train.values\n",
    "y = y.ravel()\n",
    "\n",
    "select_best = SelectKBest(mutual_info_classif, k=19) #match the number of features boruta selected\n",
    "select_best.fit(X, y)\n",
    "mi_subset = X_train.columns[select_best.get_support()]\n",
    "mi_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [0, 2, 3, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information accuracy: 0.8757530120481928\n"
     ]
    }
   ],
   "source": [
    "# MUTUAL INFO TEST\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "X_train_mi = X_train[mi_subset]\n",
    "X_test_mi = X_test[mi_subset]\n",
    "\n",
    "# one hot encode data\n",
    "nominal = ['Application mode', 'Course', \"Mother's qualification\", \"Father's qualification\", \"Father's occupation\", 'Debtor', 'Tuition fees up to date', 'Scholarship holder']\n",
    "X_train_mi_oh = one_hot(X_train_mi, X_train_mi, nominal)\n",
    "X_test_mi_oh = one_hot(X_test_mi, X_train_mi, nominal)\n",
    "\n",
    "# test the mi feature subset by finding the accuracy score\n",
    "clf = LogisticRegressionCV(random_state=1, class_weight={0:0.7, 1:0.3}, solver='newton-cholesky').fit(X_train_mi_oh, y)\n",
    "score = clf.score(X_test_mi_oh, y_test)\n",
    "print(f'Mutual information accuracy: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for multicolinearity\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "X_boruta = X_train[boruta_subset]\n",
    "X_mi = X_train[mi_subset]\n",
    "\n",
    "vif_boruta = pd.DataFrame() \n",
    "vif_mi = pd.DataFrame() \n",
    "\n",
    "vif_boruta['Feature'] = X_boruta.columns \n",
    "vif_mi['Feature'] = X_mi.columns \n",
    "  \n",
    "# calculating VIF for each feature \n",
    "vif_boruta['VIF'] = [variance_inflation_factor(X_boruta.values, i) \n",
    "                          for i in range(len(X_boruta.columns))] \n",
    "vif_mi['VIF'] = [variance_inflation_factor(X_mi.values, i) \n",
    "                          for i in range(len(X_mi.columns))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>3.260958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Course</td>\n",
       "      <td>29.218255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>13.192101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mother's occupation</td>\n",
       "      <td>6.386088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father's occupation</td>\n",
       "      <td>6.447701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Admission grade</td>\n",
       "      <td>8.922881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>1.327177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>8.751157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.619831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>1.479733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>2.518682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Curricular units 1st sem (enrolled)</td>\n",
       "      <td>128.139497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Curricular units 1st sem (evaluations)</td>\n",
       "      <td>17.782707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Curricular units 1st sem (approved)</td>\n",
       "      <td>39.114827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Curricular units 1st sem (grade)</td>\n",
       "      <td>28.659638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Curricular units 2nd sem (enrolled)</td>\n",
       "      <td>124.244453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Curricular units 2nd sem (evaluations)</td>\n",
       "      <td>16.721821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Curricular units 2nd sem (approved)</td>\n",
       "      <td>32.080347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Curricular units 2nd sem (grade)</td>\n",
       "      <td>27.107252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature         VIF\n",
       "0                         Application mode    3.260958\n",
       "1                                   Course   29.218255\n",
       "2           Previous qualification (grade)   13.192101\n",
       "3                      Mother's occupation    6.386088\n",
       "4                      Father's occupation    6.447701\n",
       "5                          Admission grade    8.922881\n",
       "6                                   Debtor    1.327177\n",
       "7                  Tuition fees up to date    8.751157\n",
       "8                                   Gender    1.619831\n",
       "9                       Scholarship holder    1.479733\n",
       "10                       Age at enrollment    2.518682\n",
       "11     Curricular units 1st sem (enrolled)  128.139497\n",
       "12  Curricular units 1st sem (evaluations)   17.782707\n",
       "13     Curricular units 1st sem (approved)   39.114827\n",
       "14        Curricular units 1st sem (grade)   28.659638\n",
       "15     Curricular units 2nd sem (enrolled)  124.244453\n",
       "16  Curricular units 2nd sem (evaluations)   16.721821\n",
       "17     Curricular units 2nd sem (approved)   32.080347\n",
       "18        Curricular units 2nd sem (grade)   27.107252"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496.9751045909627"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vif_boruta['VIF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>3.802803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Course</td>\n",
       "      <td>29.583547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Previous qualification</td>\n",
       "      <td>1.513132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>7.601451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mother's qualification</td>\n",
       "      <td>3.835881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Father's qualification</td>\n",
       "      <td>4.376275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Father's occupation</td>\n",
       "      <td>1.222005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>1.317128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>8.758926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>1.503996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>2.706466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Curricular units 1st sem (enrolled)</td>\n",
       "      <td>128.422035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Curricular units 1st sem (evaluations)</td>\n",
       "      <td>17.749874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Curricular units 1st sem (approved)</td>\n",
       "      <td>39.253572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Curricular units 1st sem (grade)</td>\n",
       "      <td>28.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Curricular units 2nd sem (enrolled)</td>\n",
       "      <td>124.683916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Curricular units 2nd sem (evaluations)</td>\n",
       "      <td>16.714232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Curricular units 2nd sem (approved)</td>\n",
       "      <td>31.912298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Curricular units 2nd sem (grade)</td>\n",
       "      <td>27.085552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature         VIF\n",
       "0                         Application mode    3.802803\n",
       "1                                   Course   29.583547\n",
       "2                   Previous qualification    1.513132\n",
       "3           Previous qualification (grade)    7.601451\n",
       "4                   Mother's qualification    3.835881\n",
       "5                   Father's qualification    4.376275\n",
       "6                      Father's occupation    1.222005\n",
       "7                                   Debtor    1.317128\n",
       "8                  Tuition fees up to date    8.758926\n",
       "9                       Scholarship holder    1.503996\n",
       "10                       Age at enrollment    2.706466\n",
       "11     Curricular units 1st sem (enrolled)  128.422035\n",
       "12  Curricular units 1st sem (evaluations)   17.749874\n",
       "13     Curricular units 1st sem (approved)   39.253572\n",
       "14        Curricular units 1st sem (grade)   28.533900\n",
       "15     Curricular units 2nd sem (enrolled)  124.683916\n",
       "16  Curricular units 2nd sem (evaluations)   16.714232\n",
       "17     Curricular units 2nd sem (approved)   31.912298\n",
       "18        Curricular units 2nd sem (grade)   27.085552"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480.57699011126357"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vif_mi['VIF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both feature subsets have a lot of multicolinearity. Let's prune out the features with the highest VIF scores and see if that affects accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUNE MULTICOLINEAR FEATURES\n",
    "\n",
    "def get_vif(df, subset):\n",
    "# recalculates vif scores after dropping a feature\n",
    "\n",
    "    X = X_train[subset]\n",
    "    \n",
    "    df['VIF'] = [variance_inflation_factor(X.values, i) \n",
    "                          for i in range(len(X.columns))] \n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_max(df):\n",
    "# iteratively drops the feature with highest vif score\n",
    "\n",
    "    while max(df['VIF'] > 50):\n",
    "\n",
    "        # drop feature with the highest vif\n",
    "        label = df.index[df['VIF'] == max(df['VIF'])]\n",
    "        df = df.drop(label, axis=0)\n",
    "\n",
    "        # recalculate VIF scores\n",
    "        subset = df['Feature'].to_list()\n",
    "        df = get_vif(df, subset)\n",
    "\n",
    "    return df\n",
    "\n",
    "# get new dataframes with the pruned feature subsets\n",
    "# use copies of the dataframes with the original subsets so they aren't altered\n",
    "new_boruta = drop_max(vif_boruta.copy())\n",
    "new_mi = drop_max(vif_mi.copy())\n",
    "\n",
    "new_boruta = new_boruta.reset_index(drop=True)\n",
    "new_mi = new_mi.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>3.258991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Course</td>\n",
       "      <td>29.071295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>13.169923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mother's occupation</td>\n",
       "      <td>6.385860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father's occupation</td>\n",
       "      <td>6.447386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Admission grade</td>\n",
       "      <td>8.922251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>1.327148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>8.742941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.618546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>1.476391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>2.491538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Curricular units 1st sem (evaluations)</td>\n",
       "      <td>14.163712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Curricular units 1st sem (approved)</td>\n",
       "      <td>26.994073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Curricular units 1st sem (grade)</td>\n",
       "      <td>26.367960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Curricular units 2nd sem (enrolled)</td>\n",
       "      <td>42.177762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Curricular units 2nd sem (evaluations)</td>\n",
       "      <td>16.047328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Curricular units 2nd sem (approved)</td>\n",
       "      <td>29.869024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Curricular units 2nd sem (grade)</td>\n",
       "      <td>27.070495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature        VIF\n",
       "0                         Application mode   3.258991\n",
       "1                                   Course  29.071295\n",
       "2           Previous qualification (grade)  13.169923\n",
       "3                      Mother's occupation   6.385860\n",
       "4                      Father's occupation   6.447386\n",
       "5                          Admission grade   8.922251\n",
       "6                                   Debtor   1.327148\n",
       "7                  Tuition fees up to date   8.742941\n",
       "8                                   Gender   1.618546\n",
       "9                       Scholarship holder   1.476391\n",
       "10                       Age at enrollment   2.491538\n",
       "11  Curricular units 1st sem (evaluations)  14.163712\n",
       "12     Curricular units 1st sem (approved)  26.994073\n",
       "13        Curricular units 1st sem (grade)  26.367960\n",
       "14     Curricular units 2nd sem (enrolled)  42.177762\n",
       "15  Curricular units 2nd sem (evaluations)  16.047328\n",
       "16     Curricular units 2nd sem (approved)  29.869024\n",
       "17        Curricular units 2nd sem (grade)  27.070495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Application mode</td>\n",
       "      <td>3.801697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Course</td>\n",
       "      <td>29.449891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Previous qualification</td>\n",
       "      <td>1.512306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>7.586888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mother's qualification</td>\n",
       "      <td>3.828542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Father's qualification</td>\n",
       "      <td>4.376272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Father's occupation</td>\n",
       "      <td>1.222002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>1.317117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>8.749660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>1.499432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>2.685508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Curricular units 1st sem (evaluations)</td>\n",
       "      <td>14.131533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Curricular units 1st sem (approved)</td>\n",
       "      <td>27.040368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Curricular units 1st sem (grade)</td>\n",
       "      <td>26.223545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Curricular units 2nd sem (enrolled)</td>\n",
       "      <td>42.299580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Curricular units 2nd sem (evaluations)</td>\n",
       "      <td>16.037261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Curricular units 2nd sem (approved)</td>\n",
       "      <td>29.638290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Curricular units 2nd sem (grade)</td>\n",
       "      <td>27.047540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature        VIF\n",
       "0                         Application mode   3.801697\n",
       "1                                   Course  29.449891\n",
       "2                   Previous qualification   1.512306\n",
       "3           Previous qualification (grade)   7.586888\n",
       "4                   Mother's qualification   3.828542\n",
       "5                   Father's qualification   4.376272\n",
       "6                      Father's occupation   1.222002\n",
       "7                                   Debtor   1.317117\n",
       "8                  Tuition fees up to date   8.749660\n",
       "9                       Scholarship holder   1.499432\n",
       "10                       Age at enrollment   2.685508\n",
       "11  Curricular units 1st sem (evaluations)  14.131533\n",
       "12     Curricular units 1st sem (approved)  27.040368\n",
       "13        Curricular units 1st sem (grade)  26.223545\n",
       "14     Curricular units 2nd sem (enrolled)  42.299580\n",
       "15  Curricular units 2nd sem (evaluations)  16.037261\n",
       "16     Curricular units 2nd sem (approved)  29.638290\n",
       "17        Curricular units 2nd sem (grade)  27.047540"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [0, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [0, 2, 3, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boruta: 0.875\n",
      "Mutual info: 0.8772590361445783\n"
     ]
    }
   ],
   "source": [
    "# TEST NEW FEATURE SUBSETS\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# boruta data\n",
    "X_train_boruta = X_train[new_boruta['Feature'].to_list()]\n",
    "X_test_boruta = X_test[new_boruta['Feature'].to_list()]\n",
    "\n",
    "# one hot encode boruta data\n",
    "nominal = ['Application mode', 'Course', \"Mother's occupation\", \"Father's occupation\", 'Debtor', 'Tuition fees up to date', 'Gender', 'Scholarship holder']\n",
    "X_train_boruta_oh = one_hot(X_train_boruta, X_train_boruta, nominal)\n",
    "X_test_boruta_oh = one_hot(X_test_boruta, X_train_boruta, nominal)\n",
    "\n",
    "# mutual info data\n",
    "X_train_mi = X_train[new_mi['Feature'].to_list()]\n",
    "X_test_mi = X_test[new_mi['Feature'].to_list()]\n",
    "\n",
    "# one hot encode mutual info data\n",
    "nominal = ['Application mode', 'Course', \"Mother's qualification\", \"Father's qualification\", \"Father's occupation\", 'Debtor', 'Tuition fees up to date', 'Scholarship holder']\n",
    "X_train_mi_oh = one_hot(X_train_mi, X_train_mi, nominal)\n",
    "X_test_mi_oh = one_hot(X_test_mi, X_train_mi, nominal)\n",
    "\n",
    "# test boruta data\n",
    "clf = LogisticRegressionCV(random_state=1, class_weight={0:0.7, 1:0.3}, solver='newton-cholesky').fit(X_train_boruta_oh, y)\n",
    "score = clf.score(X_test_boruta_oh, y_test)\n",
    "print(f'Boruta: {score}')\n",
    "\n",
    "# test mutual info data\n",
    "clf = LogisticRegressionCV(random_state=1, class_weight={0:0.7, 1:0.3}, solver='newton-cholesky').fit(X_train_mi_oh, y)\n",
    "score = clf.score(X_test_mi_oh, y_test)\n",
    "print(f'Mutual info: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some trial and error, setting the VIF threshold to 50 allows us to get accuracy scores that are equal to or slighly better than the original boruta and mutual info subsets. Thresholds < 50 reduce accuracy, and thresholds > 50 stop improving it. The two subsets are nearly the same and are very close in terms of model accuracy and overall VIF scores. In my opinion, the Boruta subset is a bit easier to interpret, so we'll go with that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Application mode',\n",
       " 'Course',\n",
       " 'Previous qualification (grade)',\n",
       " \"Mother's occupation\",\n",
       " \"Father's occupation\",\n",
       " 'Admission grade',\n",
       " 'Debtor',\n",
       " 'Tuition fees up to date',\n",
       " 'Gender',\n",
       " 'Scholarship holder',\n",
       " 'Age at enrollment',\n",
       " 'Curricular units 1st sem (evaluations)',\n",
       " 'Curricular units 1st sem (approved)',\n",
       " 'Curricular units 1st sem (grade)',\n",
       " 'Curricular units 2nd sem (enrolled)',\n",
       " 'Curricular units 2nd sem (evaluations)',\n",
       " 'Curricular units 2nd sem (approved)',\n",
       " 'Curricular units 2nd sem (grade)',\n",
       " 'Target']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_subset = new_boruta['Feature'].to_list()\n",
    "final_subset.append('Target')\n",
    "final_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [0, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create and save the final, preprocessed dataset that will be used \n",
    "\n",
    "nominal=['Application mode','Course',\"Mother's occupation\",\"Father's occupation\",'Debtor','Tuition fees up to date','Gender','Scholarship holder']\n",
    "\n",
    "all_data = pd.read_csv('LogReg/data_clean.csv')\n",
    "data_subset =  all_data[final_subset]\n",
    "\n",
    "X = data_subset.drop('Target', axis=1)\n",
    "y = data_subset['Target']\n",
    "\n",
    "X = scale(X, nominal)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "X_train_oh = one_hot(X_train, X_train, nominal)\n",
    "X_test_oh = one_hot(X_test, X_train, nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oh.to_csv('LogReg/X_train.csv', index=False)\n",
    "X_test_oh.to_csv('LogReg/X_test.csv', index=False)\n",
    "y_train.to_csv('LogReg/y_train.csv', index=False)\n",
    "y_test.to_csv('LogReg/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "X_train = pd.read_csv('LogReg/X_train.csv')\n",
    "X_test = pd.read_csv('LogReg/X_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('LogReg/y_train.csv')\n",
    "y_test = pd.read_csv('LogReg/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla\n",
    "\n",
    "Let's inspect the perfomance of the vanilla model to compare for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, make_scorer, ConfusionMatrixDisplay, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1fe2a78c820>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "\n",
    "clf_vanilla = LogisticRegression().fit(X_train, y_train)\n",
    "ConfusionMatrixDisplay.from_estimator(clf_vanilla, X_test, y_test, normalize='true', colorbar=False)\n",
    "RocCurveDisplay.from_estimator(clf_vanilla, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.48% of true negative cases are falsely predicted. 29% of true positive cases are falsely predicted. That's a huge rate of false negatives. We'd rather have some bias toward false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use grid search to evaluate the different possible parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "140 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.6711887         nan        nan        nan 0.6711887\n",
      " 0.6711887  0.68152431 0.6711887  0.6711887  0.6711887  0.6711887\n",
      "        nan 0.70899161        nan        nan        nan 0.8091073\n",
      " 0.82040909 0.79586273 0.82040909 0.82040909 0.82040909 0.82040909\n",
      "        nan 0.85368284        nan        nan        nan 0.8527151\n",
      " 0.85497733 0.85594142 0.85529991 0.85529991 0.85529991 0.85529991\n",
      "        nan 0.8727422         nan        nan        nan 0.87274272\n",
      " 0.86951066 0.86854187 0.86918756 0.86918756 0.86918756 0.86918756\n",
      "        nan 0.86886654        nan        nan        nan 0.86854396\n",
      " 0.87015738 0.8701579  0.8701579  0.8701579  0.8701579  0.8701579\n",
      "        nan 0.86725103        nan        nan        nan 0.86886706\n",
      " 0.86886706 0.86886654 0.86854396 0.86854396 0.86822138 0.86886758\n",
      "        nan 0.86628225        nan        nan        nan 0.86886706\n",
      " 0.86757569 0.86757413 0.86789671 0.86757413 0.86854396 0.86886706]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the train scores are non-finite: [       nan 0.67118863        nan        nan        nan 0.67118863\n",
      " 0.67118863 0.68071701 0.67118863 0.67118863 0.67118863 0.67118863\n",
      "        nan 0.71422457        nan        nan        nan 0.80910845\n",
      " 0.8207364  0.80095264 0.82081714 0.8207364  0.8207364  0.8207364\n",
      "        nan 0.85788143        nan        nan        nan 0.85440919\n",
      " 0.86506793 0.86450273 0.86506793 0.86522942 0.86522942 0.86522942\n",
      "        nan 0.88307515        nan        nan        nan 0.88259069\n",
      " 0.88137925 0.8817829  0.88137925 0.88146    0.88146    0.88146\n",
      "        nan 0.88727407        nan        nan        nan 0.88703184\n",
      " 0.88678948 0.88751633 0.88703177 0.88695103 0.88695103 0.88703177\n",
      "        nan 0.88743552        nan        nan        nan 0.88711252\n",
      " 0.88711252 0.88719326 0.88711252 0.88719326 0.88719326 0.88695103\n",
      "        nan 0.88735478        nan        nan        nan 0.887274\n",
      " 0.88719329 0.88751626 0.88751626 0.88751626 0.88743552 0.88719326]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.                nan        nan        nan 0.\n",
      " 0.         0.03239158 0.         0.         0.         0.\n",
      "        nan 0.13576741        nan        nan        nan 0.51767121\n",
      " 0.50979426 0.43022795 0.50979426 0.50979426 0.50979426 0.50979426\n",
      "        nan 0.64145658        nan        nan        nan 0.64146141\n",
      " 0.65226987 0.63750604 0.65325027 0.65325027 0.65325027 0.65325027\n",
      "        nan 0.7200425         nan        nan        nan 0.72102289\n",
      " 0.70531247 0.69942529 0.70433208 0.70531247 0.70531247 0.70531247\n",
      "        nan 0.72691973        nan        nan        nan 0.72495895\n",
      " 0.71906211 0.71905728 0.72003767 0.72003767 0.72003767 0.72003767\n",
      "        nan 0.72691007        nan        nan        nan 0.7269149\n",
      " 0.7269149  0.7278953  0.7269149  0.7269149  0.72593451 0.72495412\n",
      "        nan 0.72592968        nan        nan        nan 0.7269149\n",
      " 0.7269149  0.72691007 0.72789047 0.72691007 0.7269149  0.7269149 ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the train scores are non-finite: [       nan 0.                nan        nan        nan 0.\n",
      " 0.         0.02922265 0.         0.         0.         0.\n",
      "        nan 0.15367269        nan        nan        nan 0.51768107\n",
      " 0.51203539 0.44179648 0.51228079 0.51203539 0.51203539 0.51203539\n",
      "        nan 0.64882471        nan        nan        nan 0.64685971\n",
      " 0.67092416 0.65618969 0.67141526 0.67141526 0.67141526 0.67141526\n",
      "        nan 0.73919658        nan        nan        nan 0.73919627\n",
      " 0.7222508  0.72298669 0.72225019 0.72249619 0.72249619 0.72249619\n",
      "        nan 0.75466725        nan        nan        nan 0.75368505\n",
      " 0.75073755 0.75196575 0.75122895 0.75098325 0.75098325 0.75098325\n",
      "        nan 0.75884265        nan        nan        nan 0.75663225\n",
      " 0.75663225 0.75761445 0.75736905 0.75761445 0.75687795 0.75540435\n",
      "        nan 0.75884265        nan        nan        nan 0.75736844\n",
      " 0.75908774 0.75884265 0.75884265 0.75884265 0.75884265 0.75687765]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.                nan        nan        nan 0.\n",
      " 0.         0.06243461 0.         0.         0.         0.\n",
      "        nan 0.22112412        nan        nan        nan 0.64037757\n",
      " 0.65042173 0.58046591 0.65042173 0.65042173 0.65042173 0.65042173\n",
      "        nan 0.74229171        nan        nan        nan 0.74121894\n",
      " 0.7473992  0.74420342 0.74810096 0.74810096 0.74810096 0.74810096\n",
      "        nan 0.78819607        nan        nan        nan 0.78843258\n",
      " 0.78034071 0.77765023 0.77963728 0.77987524 0.77987524 0.77987524\n",
      "        nan 0.78479128        nan        nan        nan 0.78387433\n",
      " 0.78457759 0.78460404 0.78481442 0.78481442 0.78481442 0.78481442\n",
      "        nan 0.78268249        nan        nan        nan 0.78481191\n",
      " 0.78481191 0.78501788 0.78438773 0.78438773 0.78375433 0.7843721\n",
      "        nan 0.78122709        nan        nan        nan 0.78481191\n",
      " 0.7831483  0.78311898 0.78374591 0.78311898 0.78438773 0.78481191]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melanie\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the train scores are non-finite: [       nan 0.                nan        nan        nan 0.\n",
      " 0.         0.05674837 0.         0.         0.         0.\n",
      "        nan 0.24390965        nan        nan        nan 0.64070762\n",
      " 0.65252476 0.59341061 0.65273252 0.65252476 0.65252476 0.65252476\n",
      "        nan 0.75013392        nan        nan        nan 0.74501072\n",
      " 0.76580639 0.7610372  0.76593711 0.76615271 0.76615271 0.76615271\n",
      "        nan 0.80609829        nan        nan        nan 0.80544951\n",
      " 0.80015806 0.8008617  0.80015769 0.80031932 0.80031932 0.80031932\n",
      "        nan 0.81490629        nan        nan        nan 0.81438576\n",
      " 0.81346566 0.8146875  0.81388993 0.81373188 0.81373188 0.81384078\n",
      "        nan 0.81595122        nan        nan        nan 0.81508001\n",
      " 0.81507812 0.81537913 0.8152231  0.81537913 0.81523241 0.81461905\n",
      "        nan 0.81584106        nan        nan        nan 0.81544196\n",
      " 0.81568047 0.81605609 0.81605609 0.81605609 0.81595122 0.81523597]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define possible parameters\n",
    "parameters = {'penalty':['l1', 'l2'], # exclude penalties 'none' and 'elasticnet' because they will produce NaN\n",
    "              'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "              'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]} # use logarithmic scale to test wide range of C values\n",
    "\n",
    "# fit \n",
    "lrg = LogisticRegression()\n",
    "f1 = make_scorer(f1_score)\n",
    "clf = GridSearchCV(lrg, parameters, scoring=['accuracy', 'recall', 'f1'], return_train_score=True, refit=False)\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_train = y_train.ravel()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# see results\n",
    "gs_results = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the results dataframe and reformat into a digestible form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with NaN\n",
    "# these rows represent incompatible parameter combinations\n",
    "gs_results = gs_results.dropna(axis=0)\n",
    "\n",
    "# columns of interest\n",
    "columns = ['param_C', 'param_penalty', 'param_solver', \n",
    "           'mean_test_accuracy', \n",
    "           'mean_test_recall', \n",
    "           'mean_test_f1']\n",
    "\n",
    "# sort by mean_test_score\n",
    "gs_recall = gs_results[columns].sort_values(by='mean_test_recall', axis=0, ascending=False, ignore_index=True)\n",
    "gs_accuracy = gs_results[columns].sort_values(by='mean_test_accuracy', axis=0, ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.868867</td>\n",
       "      <td>0.727895</td>\n",
       "      <td>0.785018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.867897</td>\n",
       "      <td>0.727890</td>\n",
       "      <td>0.783746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.868867</td>\n",
       "      <td>0.726920</td>\n",
       "      <td>0.784791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.868867</td>\n",
       "      <td>0.726915</td>\n",
       "      <td>0.784812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>0.868544</td>\n",
       "      <td>0.726915</td>\n",
       "      <td>0.784388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_penalty     param_solver  mean_test_accuracy  \\\n",
       "0    100.0            l2        liblinear            0.868867   \n",
       "1   1000.0            l2        newton-cg            0.867897   \n",
       "2     10.0            l1        liblinear            0.868867   \n",
       "3   1000.0            l2             saga            0.868867   \n",
       "4    100.0            l2  newton-cholesky            0.868544   \n",
       "\n",
       "   mean_test_recall  mean_test_f1  \n",
       "0          0.727895      0.785018  \n",
       "1          0.727890      0.783746  \n",
       "2          0.726920      0.784791  \n",
       "3          0.726915      0.784812  \n",
       "4          0.726915      0.784388  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VIEW HIGHEST RECALL\n",
    "gs_recall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.872743</td>\n",
       "      <td>0.721023</td>\n",
       "      <td>0.788433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.872742</td>\n",
       "      <td>0.720042</td>\n",
       "      <td>0.788196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.870158</td>\n",
       "      <td>0.720038</td>\n",
       "      <td>0.784814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.870158</td>\n",
       "      <td>0.719057</td>\n",
       "      <td>0.784604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.870158</td>\n",
       "      <td>0.720038</td>\n",
       "      <td>0.784814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_penalty param_solver  mean_test_accuracy  mean_test_recall  \\\n",
       "0      1.0            l1         saga            0.872743          0.721023   \n",
       "1      1.0            l1    liblinear            0.872742          0.720042   \n",
       "2     10.0            l2         saga            0.870158          0.720038   \n",
       "3     10.0            l2    liblinear            0.870158          0.719057   \n",
       "4     10.0            l2    newton-cg            0.870158          0.720038   \n",
       "\n",
       "   mean_test_f1  \n",
       "0      0.788433  \n",
       "1      0.788196  \n",
       "2      0.784814  \n",
       "3      0.784604  \n",
       "4      0.784814  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VIEW HIGHEST ACCURACY\n",
    "gs_accuracy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Model R be the model with the highest recall. Let Model A be the model with the highest accuracy. Model A has a significant improvement in accuracy at the cost of only a slight decrease in recall. We'll proceed with Model A and tune the decision threshold to achieve a higher ratio of false positives. <br>\n",
    "Overall, it seems that the model is not very sensitive to penalty or solver, and only slightly sensitive to C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1fe2a794a00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARIAAAEICAYAAACTenveAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApY0lEQVR4nO3deZgU1bnH8e+PRUFARIV7EVQQJRFlUUYRBFk0hEWjRCPiFr1u3LhFrgQSDWgWlytXCXFBVKJGBY2KIiFoMAgmoiw6IosoCuIoCoIiSFBG3vtH1Yw9PT3T1TNT093wfp5nnuna366ZfvvUqXNOycxwzrnqqJPtAJxz+c8TiXOu2jyROOeqzROJc67aPJE456rNE4lzrtpiSySSJktaL2lpBcslaYKkVZKWSDo6rlicc/GqF+O+HwTuBB6uYPlA4LDwpxtwT/i7Uvvvv7+1adOmZiJ0zqW0ePHiz8ysedT1Y0skZjZPUptKVjkVeNiCFnGvStpHUkszW1fZftu0acOiRYtqMlTnas1jr63l2cKPsh1GhTocsDdjTzkCSR9ksl2cJZJ0WgEfJkwXhfPKJRJJlwKXAhx00EG1EpxzNakkgby2ehMA3drum+WIalY2E4lSzEvZXt/MJgGTAAoKCrxNv8sJmZQuEhPIqV1acXa3XesLMZuJpAg4MGG6NfBxlmJxLpLE5JFJ6WJXTSAlsplIpgNXSJpKUMm6OV39iHO1paLSRmLy2NWTQyZiSySSpgB9gP0lFQFjgfoAZjYRmAkMAlYB24AL44rF7briqrysqLThySO1OO/aDEuz3IDL4zq+y39RkkRclZeeMDKTzUsb50qlShpRkoR/4HODJxJXayorYaRKGp4k8ocnEldj0l2KVFbC8KSR3zyRuCpLThzpLkU8Wey6PJG4jFXUStMTxe7LE4mrVLpKUE8cDjyRuCRRLlc8gbhknkh2Q5ncPfGk4aLwRLKbiNpHxBOHqwpPJLu4VBWjnixcTfNEkscybULuycPFxRNJnvAm5C6XeSLJE88WfsTydV/SoeXepfM8Sbhc4YkkhyWWQkqSyOOXdc9yVM6VFymRSKoDdAYOAP4NLDOzT+MMbHf32Gtr+dW0t4Cg5NGh5d6c2qVVlqNyLrVKE4mkdsAo4CTgXWAD0ABoL2kbcC/wkJntjDvQXV1FDcFuGtLRL11czktXIvkdwfNmLgsHIiolqQVwNnAe8FA84e36vN+K2xVUmkgqG+XMzNYD42s6oN1J8uWLJw6Xr6pc2SrpB2b295oMZleVbiBhv3xx+a46d20eAPy/P43kUkciL4W4XUW6ytbpFS0C9qv5cHY9JSURL3W4XVm6Ekkv4Fxga9J8AcfGEtEu5LHX1vLa6k10a7uvJxG3S0uXSF4FtpnZ3OQFklbGE1J+S9XL1tt/uF1durs2AytZdkLNh5O/vJet2515E/lqSpVAPHm43Y0nkmrwdiDOBTyRVIPfkXEuUCfbAeQ7vyPjXAaJRNINlU3vLh57bS1D753P0Hvns3zdl9kOx7mckMmlzeI007usigZO9q79zgUiJxIze66y6V1Z4uhkXqnqXHnpmsj/EbCKlpvZVTUeUY7y0cmcq1i6EsmiWokihyU2c3fOpZauZWuZAYskNTKzr+INKTckNzTzuhDnKhbpro2k7pKWAyvC6c6S7o6w3QBJKyWtkjQ6xfKmkp6T9KakZZIuzPgdxKSkXqRb2329nYhzaUStbB0P/BCYDmBmb0qqtK+NpLrAXcAPgCJgoaTpZrY8YbXLgeVmdoqk5sBKSY+a2TcZvo8alXg54/UizqUXuR2JmX2YNOvbNJscC6wys/fDxDAVODV5t0ATSQIaA5uA4qgxxaXkVq9fzjgXTdRE8qGkHoBJ2kPStYSXOZVoBSQmn6JwXqI7gcOBj4G3gKtTjUgv6VJJiyQt2rBhQ8SQq8bHEHEuc1ETyXCCy5BWwEdAl3C6MkoxL/lW8g+BQoLn5XQB7pS0d9I6mNkkMysws4LmzZtHDLlqvDTiXOYi1ZGY2WfAORnuuwg4MGG6NUHJI9GFwC3hoy5WSVoNfB9YkOGxaoSXRpyrmqh3bQ4J765skLRe0rOSDkmz2ULgMEltJe0BnEVYWZtgLXBieIz/AL4HvJ/ZW6g5XhpxrmqiXto8BjwBtCS4DPkLMKWyDcysGLgCeJ6gPuUJM1smabik4eFqvwV6SHoLeBEYFZZ+ap2XRpyruqi3f2Vmf06YfkTSFek2MrOZwMykeRMTXn8M9I8YQ6y8NOJc1aXra1PSLnxO2KBsKkGF6VDgrzHHVmu8NOJc9aQrkSwmSBwld2AuS1hmBJcmeS1xuEQvjThXNen62rStrUBqU6rxRbwZvHNVF3k8EklHAh2ABiXzzOzhOIKKU/KAzT6+iHPVFymRSBoL9CFIJDOBgcA/gbxKJIlJxEsgztWcqLd/zyBo7/GJmV0IdAb2jC2qGHgScS4+URPJv8M+MMVhE/b1QLoGaTnDk4hz8YpaR7JI0j7AfQR3craSpWbsVeHPn3EuXlH72vwsfDlR0ixgbzNbEl9YNc/biDgXn3QN0o6ubJmZvV7zIdWcktu8JSPAO+fika5E8n+VLDOgXw3GUuMSk4g3NnMuPukapPWtrUDi4o+RcC5+u+yzf0v6zzjn4rdLJhLvP+Nc7dolE4nf7nWudkUdIU2SzpU0Jpw+SNKx8YZWPX6717naE7VEcjfQHRgWTm8heGaNc85FbtnazcyOlvQGgJl9Ho7D6pxzkUskO8In5xlA+FS8cs+fcc7tnqImkgnANKCFpN8TDCFwU2xRVYPf9nWu9kXta/OopMUEQwkIOM3M0j1pLyt8EGfnal/UgY3+ADxuZnlRwep3bJyrXVEvbV4Hrpe0StJtkgriDMo5l18iJRIze8jMBgHHAu8At0p6N9bInHN5I9OWrYcSPJu3DfB2jUfjnMtLUVu2lpRAfgMsA7qa2SmxRuacyxtRG6StBrpn67m8zrnclm6EtO+b2dsE47MeJKnMrZBcHyHNOVc70pVIRgCXknqktJwbIS3xGb7OudqTboS0S8OXA81se+IySQ1SbJJV3hjNueyIetfmlYjzss4bozlX+9LVkfwn0ApoKOkogubxAHsDe8Ucm3MuT6SrI/khcAHQGrg9Yf4W4FcxxeScyzPp6kgeAh6SdLqZPZXpziUNAP4A1AXuN7NbUqzTBxgP1Ac+M7PemR7HOZdd6S5tzjWzR4A2kkYkLzez21NsVrJtXYJR1H4AFAELJU03s+UJ6+xDMPraADNbK6lF1d6Gcy6b0lW2Ngp/NwaapPipzLHAKjN738y+AaYCpyatczbwtJmtBTCz9RnEXoaPQ+Jc9qS7tLk3/H1jFfbdCvgwYboI6Ja0TnugvqSXCBLTH8zs4Socy2/9OpdFUfva/K+kvSXVl/SipM8knZtusxTzLGm6HtAVGExQsftrSe1THP9SSYskLdqwYUOFB/Rbv85lR9R2JP3N7EvgZIKSRXtgZJptioADE6ZbAx+nWGeWmX0V9uOZB3RO3pGZTTKzAjMraN68ecSQnXO1JWoiqR/+HgRMMbMolRELgcMktQ1HnD8LmJ60zrNAL0n1JO1FcOmTk0M4OucqFrX373OS3gb+DfwsHEV+e2UbmFmxpCuA5wlu/042s2WShofLJ5rZCkmzgCUEo9Lfb2ZLq/pmnHPZEXXw59GSbgW+NLNvJX1F+TswqbabCcxMmjcxafo24LboITvnck3UwZ/rA+cBJ0gCmAtMrHQj59xuI+qlzT0E9SR3h9PnhfMujiMo51x+iZpIjjGzxLsp/5D0ZhwBVYWPQ+JcdkW9a/OtpHYlE5IOAb6NJ6TMeWM057IraolkJDBH0vsEDc0OBi6MLaoq8MZozmVP2kQS3urdTNB3pgVBInnbzL6OOTbnXJ6o9NJG0sUEj5/4I1AItDGzNz2JOOcSpSuR/Bw4wsw2hPUij1K+dapzbjeXrrL1GzPbAGBm7wN7xh+Scy7fpCuRtJY0oaJpM7sqnrCcc/kkXSJJ7uG7OK5AnHP5K8qYrc45V6l0d20mSTqygmWNJP2XpHPiCc05ly/SXdrcDYyR1BFYCmwAGgCHETzbZjLBnRzn3G4s3aVNIXCmpMZAAdCSYEySFWa2Mv7w0vN+Ns5lX9TxSLYCL8UbStV4Pxvnsi9qp72c5v1snMuuXSKROOeyK6NEIqlR+rWcc7ubqM+16SFpOeEI75I6S7o7zWbOud1E1BLJHQQPsNoIYGZvAifEFZRzLr9EvrQxsw+TZuXMCGnOueyKOkLah5J6ABY+7Ooq/EFWzrlQ1BLJcOByggeDFwFdgJ/FFJNzLs9ELZF8z8zK9KmRdDzwr5oPyTmXb6KWSP4YcZ5zbjdUaYlEUnegB9Bc0oiERXsTPM83q7yfjXO5Id2lzR5A43C9JgnzvwTOiCuoqLyfjXO5IV3v37nAXEkPmtkHtRRTRryfjXPZF7WydZuk24AjCMYjAcDM+sUSlXMur0StbH0UeBtoC9wIrAEWxhSTcy7PRE0k+5nZA8AOM5trZv8FHBdjXM65PBL10mZH+HudpMHAx0DreEJyzuWbqInkd5KaAv9D0H5kb4Kn8DnnXLRLGzObYWabzWypmfU1s67ApnTbSRogaaWkVZJGV7LeMZK+lZT1W8rOucylexxFXUnDJF1b8lgKSSdLegW4M922wF3AQKADMExShwrWuxV4vorvwTmXZekubR4ADgQWABMkfQB0B0ab2TNptj0WWBU+MxhJU4FTgeVJ610JPAUck1nozrlckS6RFACdzGynpAbAZ8ChZvZJhH23AhLHMCkCuiWuIKkVMAToRyWJRNKlwKUABx3kjc+cyzXp6ki+MbOdAGa2HXgnYhIBUIp5ljQ9HhhlZpUOkmRmk8yswMwKmjdvHvHwzrnakq5E8n1JS8LXAtqF0wLMzDpVsm0RwWVRidYEt40TFQBTJQHsDwySVBzhssk5l0PSJZLDq7HvhcBhktoCHwFnAWcnrmBmbUteS3oQmOFJxLn8k67TXpU76plZsaQrCO7G1AUmm9kyScPD5ROrum/nXG6J2iCtSsxsJjAzaV7KBGJmF8QZi3MuPv6kPedctUVOJJIaSvpenME45/JT1CftnQIUArPC6S6SpscYl3Muj0QtkdxA0FL1CwAzKwTaxBGQcy7/RE0kxWa2OdZIMlQy8LNzLvui3rVZKulsoK6kwwietPdKfGGl5wM/O5c7opZIriQYr/Vr4DFgMzkwHokP/OxcbsjkSXvXAdfFGYxzLj9FLZHcLultSb+VdESsETnn8k7UEdL6An2ADcAkSW9Juj7OwJxz+SNygzQz+8TMJgDDCdqUjIkrKOdcfonaIO1wSTdIWkowxOIr+CjyzrlQ1MrWPwFTgP5mljymiHNuNxcpkZiZPwzLOVehShOJpCfM7ExJb1F2mMQoI6Q553YT6UokV4e/T447EOdc/qq0stXM1oUvf2ZmHyT+AD+LPzznXD6Ievv3BynmDazJQJxz+StdHcl/E5Q8DkkYTR6gCfCvOANzzuWPdHUkjwF/A24GEp/du8XMvA+/cw5In0jMzNZIujx5gaR9PZk45yBaieRkYDHB7d/Ep+cZcEhMcTnn8ki659qcHP5uW9l6zrndW9S+NsdLahS+PlfS7ZJ8RCHnHBD99u89wDZJnYFfAB8Af44tKudcXslk8GcDTgX+YGZ/ILgF7JxzkXv/bpH0S+A8oJekukD9+MJyzuWTqCWSoQQDP/+XmX0CtAJuiy0q51xeiTrU4ifAo0BTSScD283s4Vgjc87ljah3bc4EFgA/Ac4EXpN0RpyBOefyR9Q6kuuAY8xsPYCk5sBs4Mm4AnPO5Y+odSR1SpJIaGMG2zrndnFRSySzJD1PMG4rBJWvM+MJyTmXb6KO2TpS0o+BngT9bSaZ2bRYI3PO5Y1KL08kHSbp2fAxFD8B/s/MromaRCQNkLRS0ipJo1MsP0fSkvDnlbDlrHMuz6Sr55gMzABOJ+gB/MeoOw4brd1FMJJaB2CYpA5Jq60GeoeDSP8WmBR1/8653JHu0qaJmd0Xvl4p6fUM9n0ssMrM3geQNJWgif3ykhXM7JWE9V/FH7rlXF5Kl0gaSDqK78YhaZg4bWaVJZZWwIcJ00VAt0rWv4hgNLZyJF0KXApw0EHe6di5XJMukawDbk+Y/iRh2oB+lWyrFPMsxTwk9SVIJD1TLTezSYSXPQUFBSn34ZzLnnQDG/Wtxr6LgAMTplsD5R73KakTcD8w0Mw2VuN4zrksibNR2ULgMEltJe0BnAVMT1whHBzpaeA8M3snxlicczGK2iAtY2ZWLOkK4HmgLjDZzJZJGh4unwiMAfYD7pYEwbgnBXHF5JyLR2yJBMDMZpLUAjZMICWvLwYujjMG51z8ovb+VThW65hw+iBJx8YbmnMuX0StI7kb6A4MC6e3EDQ2c865yJc23czsaElvAJjZ52EFqnPORS6R7AibvBuUjkeyM7aonHN5JWoimQBMA1pI+j3wT+Cm2KJyzuWVqMMIPCppMXAiQYvV08xsRayROefyRqREEjYc2wY8lzjPzNbGFZhzLn9ErWz9K989RLwB0BZYCRwRU1zOuTwS9dKmY+K0pKOBy2KJyDmXd6rU1yYcPuCYGo7FOZenotaRjEiYrAMcDWyIJSLnXN6JWkeS+MDwYoI6k6dqPhznXD5Km0jChmiNzWxkLcTjnMtD6UaRr2dm3xJcyjjnXErpSiQLCJJIoaTpwF+Ar0oWmtnTMcbmnMsTUetI9iV4TGc/vmtPYgSjmznndnPpEkmL8I7NUr5LICXybhDmHTt2UFRUxPbt27MdinM5oUGDBrRu3Zr69etXaz/pEkldoDEZjAify4qKimjSpAlt2rQhHNrRud2WmbFx40aKiopo27ZttfaV9nEUZvabah0hh2zfvt2TiHMhSey3335s2FD9JmHpWrbm5CfusdfW8trqTVXa1pOIc9+pqc9DukRyYo0cpYY9W/gRAKd2aZXlSJxzkCaRmFnVvvZrQbe2+3J2t/x7fGfjxo2rvY9FixZx1VVXVbh8zZo1PPbYY5HXB2jTpg0dO3akU6dO9O7dmw8++KDacdaUiRMn8vDDD9fIvtatW8fJJ59cZt7VV19Nq1at2Lnzu0H/brjhBsaNG1dmvTZt2vDZZ58B8Mknn3DWWWfRrl07OnTowKBBg3jnneo9munrr79m6NChHHrooXTr1o01a9akXO/xxx+nU6dOHHHEEfziF78onX/77bfToUMHOnXqxIknnlj6N9ywYQMDBgyoVmzpxPmALBeTgoICJkyYUOHy5ESSbv0Sc+bMYcmSJfTp04ff/e531Y7TzMp8OKtq+PDhnH/++dXeDwQftksuuaR0eufOnUybNo0DDzyQefPmRdqHmTFkyBD69OnDe++9x/Lly7npppv49NNPqxXbAw88QLNmzVi1ahXXXHMNo0aNKrfOxo0bGTlyJC+++CLLli3j008/5cUXXwTgqKOOYtGiRSxZsoQzzjijNMk0b96cli1b8q9//ata8VUm1ufa5LIbn1vG8o+/rNF9djhgb8aekvkQLYWFhQwfPpxt27bRrl07Jk+eTLNmzVi4cCEXXXQRjRo1omfPnvztb39j6dKlvPTSS4wbN44ZM2Ywd+5crr76aiC43p03bx6jR49mxYoVdOnShZ/+9KccddRRpetv3bqVK6+8kkWLFiGJsWPHcvrpp5eJp3v37qWJZ8OGDQwfPpy1a4MxrMaPH8/xxx/Phg0bOPvss9m4cSPHHHMMs2bNYvHixWzdupWBAwfSt29f5s+fzzPPPMMTTzzBE088wddff82QIUO48cYb+eqrrzjzzDMpKiri22+/5de//jVDhw5l9OjRTJ8+nXr16tG/f3/GjRvHDTfcQOPGjbn22msrPFd9+vShW7duzJkzhy+++IIHHniAXr16lTvXTz31VJkkOWfOHI488kiGDh3KlClT6NOnT9q/15w5c6hfvz7Dhw8vndelS5dM/+zlPPvss9xwww0AnHHGGVxxxRWYWZl6jPfff5/27dvTvHlzAE466SSeeuopTjzxRPr2/e4Ju8cddxyPPPJI6fRpp53Go48+yvHHH1/tOFPxEkkOOP/887n11ltZsmQJHTt25MYbbwTgwgsvZOLEicyfP5+6deum3HbcuHHcddddFBYW8vLLL9OwYUNuueUWevXqRWFhIddcc02Z9X/729/StGlT3nrrLZYsWUK/fuWfAz9r1ixOO+00ICj2X3PNNSxcuJCnnnqKiy8Onmd244030q9fP15//XWGDBlSmmgAVq5cyfnnn88bb7zBypUreffdd1mwYAGFhYUsXryYefPmMWvWLA444ADefPNNli5dyoABA9i0aRPTpk1j2bJlLFmyhOuvvz7yuQIoLi5mwYIFjB8/vsz8EqtXr6ZZs2bsueeepfOmTJnCsGHDGDJkCDNmzGDHjh0V/ZlKLV26lK5du6ZdD6BXr1506dKl3M/s2bPLrfvRRx9x4IHB47Lr1atH06ZN2bix7OOwDz30UN5++23WrFlDcXExzzzzDB9++GG5fT3wwAMMHDiwdLqgoICXX345UsxVsduWSKpScojD5s2b+eKLL+jduzcAP/3pT/nJT37CF198wZYtW+jRowcAZ599NjNmzCi3/fHHH8+IESM455xz+PGPf0zr1q0rPd7s2bOZOnVq6XSzZs1KX/ft25dPP/2UFi1alH5rz549m+XLl5eu8+WXX7Jlyxb++c9/Mm3aNAAGDBhQZj8HH3wwxx13HAAvvPACL7zwAkcddRQAW7du5d1336VXr15ce+21jBo1ipNPPplevXpRXFxMgwYNuPjiixk8eHC5uoyKzlWJH//4xwB07do1Zf3CunXrSr/JAb755htmzpzJHXfcQZMmTejWrRsvvPACgwcPrvBuRqZ3OTL58JqVb5qVfLxmzZpxzz33MHToUOrUqUOPHj14//33y6zzyCOPsGjRIubOnVs6r0WLFnz88ccZxZ6J3TaR5LpU/1SpjB49msGDBzNz5kyOO+64lN90yfut6MMwZ84cGjVqxAUXXMCYMWO4/fbb2blzJ/Pnz6dhw4aR42vUqFGZ9X75y19y2WXlB9RbvHgxM2fO5Je//CX9+/dnzJgxLFiwgBdffJGpU6dy55138o9//KPS95OopKRRt25diouLyy1v2LBhmVbNs2bNYvPmzXTsGAwAuG3bNvbaay8GDx7Mfvvtx7p168psv2XLFvbZZx+OOOIInnzyyUgx9erViy1btpSbP27cOE466aQy81q3bs2HH35I69atKS4uZvPmzey7777ltj3llFM45ZRTAJg0aVKZ0urs2bP5/e9/z9y5c8uUvLZv317ub1iT/NImy5o2bUqzZs1Kv7n+/Oc/07t3b5o1a0aTJk149dVXAcqUIhK99957dOzYkVGjRlFQUMDbb79NkyZNUv7zAvTv358777yzdPrzzz8vs7xhw4aMHz+ehx9+mE2bNpVbv7CwEICePXvyxBNPAEGpI3k/JX74wx8yefJktm7dCgTF9/Xr1/Pxxx+z1157ce6553Lttdfy+uuvs3XrVjZv3sygQYMYP3586bHSnauo2rdvX6akMmXKFO6//37WrFnDmjVrWL16NS+88ALbtm3jhBNOYPr06aXn8emnn6Zz587UrVuXfv368fXXX3PfffeV7mvhwoVlSgAlXn75ZQoLC8v9JCcRgB/96Ec89NBDADz55JP069cvZdJfv349EPzt7r777tLLzTfeeIPLLruM6dOn06JFizLbvPPOOxx55JGRz1WmvERSy7Zt21bm8mPEiBE89NBDpRWIhxxyCH/605+A4Dr3kksuoVGjRvTp04emTZuW29/48eOZM2cOdevWpUOHDgwcOJA6depQr149OnfuzAUXXFB6WQFw/fXXc/nll3PkkUdSt25dxo4dW3pJUKJly5YMGzaMu+66iwkTJnD55ZfTqVMniouLOeGEE5g4cSJjx45l2LBhPP744/Tu3ZuWLVvSpEmT0oRRon///qxYsYLu3bsDwe3vRx55hFWrVjFy5Ejq1KlD/fr1ueeee9iyZQunnnoq27dvx8y44447yr3fis5VFI0aNaJdu3asWrWKAw44gOeff5577723zPKePXvy3HPPMXToUK644gp69uyJJFq0aMH9998PBJcb06ZN4+c//zm33HILDRo0oE2bNowfPz5yLKlcdNFFnHfeeRx66KHsu+++Zb48unTpUppYr776at58800AxowZQ/v27QEYOXIkW7duLb3cO+igg5g+fToQlDYHDx5crfgqZWZ59dO1a1c7c+IrdubEVyxTy5cvz3ibbNqyZUvp65tvvtmuuuqqLEZT1vbt223Hjh1mZvbKK69Y586dsxtQRE8//bRdd9112Q6j1vXq1cs2bdqUclmqzwWwyDL4XHqJJIf99a9/5eabb6a4uJiDDz6YBx98MNshlVq7di1nnnkmO3fuZI899ihTzM9lQ4YMKXcnZFe3YcMGRowYUaZCvKbJIlbq5YqCggJrd8kfAXj8su4ZbbtixQoOP/zwOMJyLm+l+lxIWmxmBVH3sdtVtuZb4nQuTjX1eYg1kUgaIGmlpFWSRqdYLkkTwuVLwgdvxaZBgwZs3LjRk4lzfDceSYMGDaq9r9jqSMLR5+8CfgAUAQslTTez5QmrDQQOC3+6AfeEv2PRunVrioqKamT8Bed2BSUjpFVXnJWtxwKrzOx9AElTgVOBxERyKvBwWEv8qqR9JLU0s3Xld1d99evXr/ZIUM658uK8tGkFJHYCKArnZbqOcy7HxVkiiTLOa6SxYCVdClwKQSObUw7Yu/rROedqTJyJpAg4MGG6NZDcayjKOpjZJGASBLd/c6XDnXMuEFs7Ekn1gHcIhmv8CFgInG1myxLWGQxcAQwiqGSdYGbHptnvBuADYH/gs1iCr3kea83LlzghP2M92Myap1u5RGwlEjMrlnQF8DzBYy0mm9kyScPD5ROBmQRJZBWwDbgwwn6bA0halEmDmWzyWGtevsQJu0essTaRN7OZBMkicd7EhNcGXB5nDM65+O12LVudczUvnxPJpGwHkAGPteblS5ywG8Sad532nHO5J59LJM65HOGJxDlXbTmfSHKtB3FlIsR6ThjjEkmvSOqci3EmrHeMpG8lnVGb8SXFkDZWSX0kFUpaJqn8wKm1IMLfvqmk5yS9GcaZtqlDXCRNlrRe0tIKlmf+mcpkOLXa/iFof/IecAiwB/Am0CFpnUHA3wia2x8HvJbDsfYAmoWvB2Yj1ihxJqz3D4Lb92fk8Dndh6Aj6EHhdIscjfNXwK3h6+bAJmCPLJ3XE4CjgaUVLM/4M5XrJZLSHsRm9g1Q0oM4UWkPYjN7FdhHUsvaDpQIsZrZK2ZWMtz6qwRdAmpblHMKcCXwFLC+NoNLEiXWs4GnzWwtgJllI94ocRrQRMGw8I0JEkn5Z2bUAjObFx6/Ihl/pnI9keRTD+JM47iIIOvXtrRxSmoFDAEmkl1Rzml7oJmklyQtllQzDwnOTJQ47wQOJ+hL9hZwtZlV/8HI8cj4M5Xrgz/XWA/iWhA5Dkl9CRJJz1gjSi1KnOOBUWb2baZPlqthUWKtB3Ql6NPVEJgv6VUzeyfu4BJEifOHQCHQD2gH/F3Sy2ZWsw+grhkZf6ZyPZHUWA/iWhApDkmdgPuBgWaWjeHMo8RZAEwNk8j+wCBJxWb2TK1E+J2of//PzOwr4CtJ84DOBB1Ga0uUOC8EbrGgEmKVpNXA94EFtRNiRjL/TGWjsieDSqF6wPtAW76rxDoiaZ3BlK0YWpDDsR5E0EGxRy6f06T1HyR7la1RzunhwIvhunsBS4EjczDOe4Abwtf/QdAjfv8s/h+0oeLK1ow/UzldIrGYehBnMdYxwH7A3eG3fbHVcq/QiHHmhCixmtkKSbOAJcBO4H4zS3lbM5txAr8FHpT0FsEHdJSZZWVoAUlTgD7A/pKKgLFA/YRYM/5MeRN551y15fpdG+dcHvBE4pyrNk8kzrlq80TinKs2TyTOuWrbrRNJ2LO1MOGnTSXrbq2B4z0oaXV4rNclda/CPu6X1CF8/aukZa9UN8ZwPyXnZWnYY3WfNOt3kTSoCsdpKWlG+LqPpM2S3pC0QtLYKuzvRyU9byWdVnKewunfSDop032mOMaD6XpDh831I9/WD9/7jAjrpey1K2mcpH5RjxeH3TqRAP82sy4JP2tq4ZgjzawLMBq4N9ONzexi++75yb9KWtaj+uEB352XIwk6d6UboLsLQbuDTI0A7kuYftnMjiJoWXuupK6Z7MzMppvZLeHkaUCHhGVjzGx2FWLMJQ8CA1LM/yPB/1PW7O6JpAxJjSW9GJYW3pJUrlds+C06L+Ebu1c4v7+k+eG2f5HUOM3h5gGHhtuOCPe1VNLPw3mNJP01HL9iqaSh4fyXJBVIugVoGMbxaLhsa/j78cQSQvgterqkupJuk7QwHGfisginZT5hhy1JxyoYR+WN8Pf3JO0B/AYYGsYyNIx9cnicN1Kdx9DpwKzkmRY0d18MtAtLO6+G8U6T1CyM5SpJy8P5U8N5F0i6U1IP4EfAbWFM7UpKEpIGSnoi4dz0kfRc+Dqjv6GkMeF7XCppklSmY9K54TlaKunYcP2o5yUlq6DXrpl9AOwn6T8z2V+NylYT3Vz4Ab4l6EhVCEwjaOq8d7hsf4KWfSWN9raGv/8HuC58XRdoEq47D2gUzh8FjElxvAcJm5sDPwFeI+hw9hbQiKB7+TLgKIIP2X0J2zYNf78EFCTGlLBOSYxDgIfC13sQ9ORsSPDY0+vD+XsCi4C2KeLcmvD+/gIMCKf3BuqFr08CngpfXwDcmbD9TcC54et9CPq9NEo6RltgccJ0H2BG+Ho/YA1wBEGL1d7h/N8A48PXHwN7lhwjOQ6SmvaXTId/47UJf6t7gHOr+DfcN2H+n4FTEv5G94WvTyBsil7ReUl67wUErXMzatpOULI7PVufpZxuIl8L/m3BZQYAkuoDN0k6gaC5dSuCfhGfJGyzEJgcrvuMmRVK6k1QjP5X+KW0B8E3eSq3Sboe2EDQA/hEYJoF38JIehroRfBNPU7SrQT/ZC9n8L7+BkyQtCdBUXiemf1bUn+gU8I1flPgMGB10vYNJRUS/NMuBv6esP5Dkg4j6A1av4Lj9wd+JOnacLoBQT+jFQnrtAzPQaJekt4gOPe3EHQe28fMSkY9e4ggsUGQYB6V9AzwTAVxlGNBc/ZZwCmSniToV/ILIJO/YYm+kn5B0MdnX4IvgefCZVPC482TtLeCeqaKzktifIuAi6O+nwTrgQOqsF2N2N0TSbJzCEav6mpmOyStIfhjlwr/MU4g+Af8s6TbgM+Bv5vZsAjHGGlmT5ZMqIIKQDN7J6wjGATcLOkFM/tNlDdhZtslvUTQdX0o4T81QR+PK83s+TS7+LeZdZHUFJhBUEcygaC/yBwzG6KgYvqlCrYXwbfjysqOQdK5JagjObl0J8HxKzKY4Nv+R8CvJWXyQOjHCd7TJmChmW0JL0ui/g2R1AC4m6B0+KGkGyj7fpL7nhgVnBdJ/5FB7BVpQHBOs8LrSMpqCqwPk0hf4ODkFSQdHK5zH/AAwZB1rwLHSyqp89hLUvuIx5wHnBZu04jgsuRlSQcA28zsEWBceJxkO8KSUSpTCTpb9SLoTEb4+79LtpHUPjxmSma2GbgKuDbcpilBr1UILiNKbCG4xCvxPHBlSZ2BpKNS7P4dghJPhcLjf66wHgo4D5grqQ5woJnNIShN7ENwWZgoOaZELxGcz0sIkgpk/jcsSRqfhXUpyXdySuq0egKbw/cS5bxUVXuCns9Z4YmkrEeBAkmLCEonb6dYpw9QGBbBTwf+YGYbCD5YUyQtIfin/H6UA5rZ6wTX3QsI6kzuN7M3gI7AgvAS4zrgdyk2nwQsUVjZmuQFgm/s2RYM/wfBOCjLgdcV3EK8lzSl0jCWN4GzgP8lKB39i6D+pMQcoENJZStByaV+GNvScDp5v18B75V8cCvxU4LLwSUEd4d+Ex77EQU9ad8A7jCzL5K2mwqMDCs12yUd+1uCktbA8DeZ/g3D491HUL/1DMElb6LPFdyOn0hwCQsRzouCivT7Ux1TQa/d+cD3JBVJuiicX5+g4n5RRfHGzXv/uqyRNITgMvL6bMeSz8LzeLSZ/TpbMXgdicsaM5smab9sx7ELqAf8XzYD8BKJc67avI7EOVdtnkicc9XmicQ5V22eSJxz1eaJxDlXbf8PVOP86EfynO0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "\n",
    "clf_param_tuned = LogisticRegression(penalty='l1', solver='saga', max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf_param_tuned, X_test, y_test, normalize='true', colorbar=False)\n",
    "RocCurveDisplay.from_estimator(clf_param_tuned, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix for the hyperparameter tuned model is a slight improvement over the vanilla model, but still needs a huge reduction of false negatives. The AUC is only 0.01 higher than the vanilla model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to find the optimal threshold. Let's start with finding the max F1 score and adjust from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1fe2a5f7610>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "\n",
    "clf_desc_tuned = TunedThresholdClassifierCV(estimator=clf_param_tuned, scoring=f1, store_cv_results=True).fit(X_train, y_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf_desc_tuned, X_test, y_test, normalize='true', colorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix is far more balanced than the previous ones, but we'd rather the false positive rate be a bit higher. Let's do this by maximizing a custom scoring method which is the F1 score but with more weight given to recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1fe2a794e20>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_f1(y_true, y_pred, beta):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    custom_f1 = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "    return custom_f1\n",
    "\n",
    "custom_scorer = make_scorer(custom_f1, beta=1.7)\n",
    "\n",
    "clf_custom_tuned = TunedThresholdClassifierCV(estimator=clf_param_tuned, scoring=custom_scorer, store_cv_results=True).fit(X_train, y_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf_custom_tuned, X_test, y_test, normalize='true', colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT SCORES DEPENDENT ON BETA VALUE IN CUSTOM SCORER\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "for beta in np.arange(1, 2, 0.1):\n",
    "\n",
    "    custom_scorer = make_scorer(custom_f1, beta=beta)\n",
    "    clf_custom_tuned = TunedThresholdClassifierCV(estimator=clf_param_tuned, scoring=custom_scorer, store_cv_results=True).fit(X_train, y_train)\n",
    "    y_pred = clf_custom_tuned.predict(X_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(y_true, y_pred))\n",
    "    recall.append(recall_score(y_true, y_pred))\n",
    "    precision.append(precision_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.860693</td>\n",
       "      <td>0.748858</td>\n",
       "      <td>0.813896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.860693</td>\n",
       "      <td>0.748858</td>\n",
       "      <td>0.813896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.860693</td>\n",
       "      <td>0.748858</td>\n",
       "      <td>0.813896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.860693</td>\n",
       "      <td>0.748858</td>\n",
       "      <td>0.813896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.856928</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.818859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.856928</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.818859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.847892</td>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.833747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.7</td>\n",
       "      <td>0.824548</td>\n",
       "      <td>0.659774</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.8</td>\n",
       "      <td>0.822289</td>\n",
       "      <td>0.654917</td>\n",
       "      <td>0.875931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.822289</td>\n",
       "      <td>0.654917</td>\n",
       "      <td>0.875931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta  accuracy  precision    recall\n",
       "0   1.0  0.860693   0.748858  0.813896\n",
       "1   1.1  0.860693   0.748858  0.813896\n",
       "2   1.2  0.860693   0.748858  0.813896\n",
       "3   1.3  0.860693   0.748858  0.813896\n",
       "4   1.4  0.856928   0.738255  0.818859\n",
       "5   1.5  0.856928   0.738255  0.818859\n",
       "6   1.6  0.847892   0.713376  0.833747\n",
       "7   1.7  0.824548   0.659774  0.870968\n",
       "8   1.8  0.822289   0.654917  0.875931\n",
       "9   1.9  0.822289   0.654917  0.875931"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame({'beta':np.arange(1, 2, 0.1),\n",
    "                       'accuracy':accuracy,\n",
    "                       'precision':precision,\n",
    "                       'recall':recall})\n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
